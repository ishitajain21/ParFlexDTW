{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Parflex – Parallel FlexDTW\n",
        "\n",
        "Chunked FlexDTW with stage-2 backtrace for global alignment. Chunk length **L** (default 4000) is set in **Parameters** below; override with `L=...` in any of the entry points.\n",
        "\n",
        "**Usage**\n",
        "- **One-shot:** `best_cost, wp = Parflex.parflex(C, steps=..., weights=..., beta=0.1, L=4000)` (same as 04 align).\n",
        "- **Two-stage (e.g. compare_flex_parflex):**  \n",
        "  `C, tiled_result = Parflex.align_system_parflex(F1, F2)` →  \n",
        "  `stage2_result = Parflex.parflex_2a(tiled_result, C, beta=0.1)` →  \n",
        "  `Parflex.plot_parflex_with_chunk_S_background(tiled_result, C, flex_wp, stage2_result)`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Parameters\n",
        "\n",
        "Chunk length and other defaults. Override in function calls (e.g. `parflex(..., L=2000)` or `align_system_parflex(..., L=2000)`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Chunk size for tiling the cost matrix. Drives memory/speed tradeoff.\n",
        "DEFAULT_CHUNK_LENGTH = 4000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import plotly.graph_objects as go\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_parflex_with_chunk_S_background(tiled_result, C_global, flex_wp, parflex_res, xy=None,\n",
        "                                         chunk_length=None, use_valid_edges_only=True):\n",
        "    \"\"\"\n",
        "    Plot FlexDTW vs ParFlex paths. Background: chunk S start→edge segments (global coords).\n",
        "    Foreground: global FlexDTW path, ParFlex stitched path, best-per-segment paths.\n",
        "\n",
        "    chunk_length : used for grid lines; if None, uses tiled_result['L_block'].\n",
        "    \"\"\"\n",
        "    blocks = tiled_result['blocks']\n",
        "    L_block = tiled_result['L_block']\n",
        "    L_div = chunk_length if chunk_length is not None else L_block\n",
        "    hop = tiled_result['hop']\n",
        "    D_chunks = parflex_res['D_chunks']\n",
        "    n_row, n_col = parflex_res['n_row'], parflex_res['n_col']\n",
        "\n",
        "    L1, L2 = C_global.shape\n",
        "    base_px = 900\n",
        "    max_side = max(L1, L2)\n",
        "    scale = base_px / max_side\n",
        "    fig_width = int(max(L2 * scale, 400))\n",
        "    fig_height = int(max(L1 * scale, 400))\n",
        "\n",
        "    fig = go.Figure()\n",
        "\n",
        "    x_S, y_S = [], []\n",
        "    INF = 1e17\n",
        "\n",
        "    def edge_index_to_local_coords(edge, idx, rows, cols):\n",
        "        \"\"\"Edge 0 = top → (rows-1, idx); edge 1 = right → (idx, cols-1).\"\"\"\n",
        "        return (rows - 1, idx) if edge == 0 else (idx, cols - 1)\n",
        "\n",
        "    for b in blocks:\n",
        "        i, j = b['bi'], b['bj']\n",
        "        if i >= n_row or j >= n_col:\n",
        "            continue\n",
        "\n",
        "        S_single = b['S_single']\n",
        "        rows, cols = b['Ck_shape']\n",
        "        r_start, r_end = b['rows']\n",
        "        c_start, c_end = b['cols']\n",
        "\n",
        "        for edge in (0, 1):  # 0=top edge, 1=right edge\n",
        "            edge_len = min(L_block, cols if edge == 0 else rows)\n",
        "\n",
        "            for idx in range(edge_len):\n",
        "                if use_valid_edges_only:\n",
        "                    D_val = D_chunks[i][j][edge][idx]\n",
        "                    if not np.isfinite(D_val) or D_val >= INF:\n",
        "                        continue\n",
        "\n",
        "                lr, lc = edge_index_to_local_coords(edge, idx, rows, cols)\n",
        "                if lr < 0 or lc < 0 or lr >= rows or lc >= cols:\n",
        "                    continue\n",
        "\n",
        "                s_val = S_single[lr, lc]\n",
        "                if s_val > 0:\n",
        "                    start_local_r, start_local_c = 0, int(s_val)\n",
        "                elif s_val < 0:\n",
        "                    start_local_r, start_local_c = abs(int(s_val)), 0\n",
        "                else:\n",
        "                    start_local_r, start_local_c = 0, 0\n",
        "                g_start_r = r_start + start_local_r\n",
        "                g_start_c = c_start + start_local_c\n",
        "                g_end_r   = r_start + lr\n",
        "                g_end_c   = c_start + lc\n",
        "                if not (0 <= g_start_r < L1 and 0 <= g_start_c < L2):\n",
        "                    continue\n",
        "                if not (0 <= g_end_r < L1 and 0 <= g_end_c < L2):\n",
        "                    continue\n",
        "                x_S.extend([g_start_c, g_end_c, None])\n",
        "                y_S.extend([g_start_r, g_end_r, None])\n",
        "\n",
        "    if x_S:\n",
        "        fig.add_trace(\n",
        "            go.Scattergl(\n",
        "                x=x_S,\n",
        "                y=y_S,\n",
        "                mode=\"lines\",\n",
        "                name=\"Chunk S start→edge segments\",\n",
        "                line=dict(width=1, color=\"rgba(100,100,100,0.02)\"),  # light grey-ish\n",
        "                showlegend=False)\n",
        "        )\n",
        "    stitched_wp = parflex_res['stitched_wp']\n",
        "    if stitched_wp.size > 0:\n",
        "        fig.add_trace(\n",
        "            go.Scattergl(\n",
        "                x=stitched_wp[:, 1],   # cols (F2)\n",
        "                y=stitched_wp[:, 0],   # rows (F1)\n",
        "                mode=\"lines\",\n",
        "                name=\"ParFlex stitched (global best)\",\n",
        "                line=dict(width=6,color=\"rgba(247,14,14,0.5)\")\n",
        "            )\n",
        "        )\n",
        "    paths_per_segment = parflex_res['paths_per_segment']\n",
        "\n",
        "    for (edge_name, seg_idx), info in paths_per_segment.items():\n",
        "        path = np.array(info['path'], dtype=int)\n",
        "        if path.size == 0:\n",
        "            continue\n",
        "        fig.add_trace(\n",
        "            go.Scattergl(\n",
        "                x=path[:, 1],   # col\n",
        "                y=path[:, 0],   # row\n",
        "                mode=\"lines\",\n",
        "                name=f\"{edge_name} seg={seg_idx}\",\n",
        "                line=dict(width=3, color=\"rgba(0,128,255,0.5)\")\n",
        "            )\n",
        "        )\n",
        "    flex_wp = np.asarray(flex_wp)\n",
        "\n",
        "    if flex_wp.shape[1] == 2:\n",
        "        f1_frames = flex_wp[:, 0]\n",
        "        f2_frames = flex_wp[:, 1]\n",
        "    elif flex_wp.shape[0] == 2:\n",
        "        f1_frames = flex_wp[0, :]\n",
        "        f2_frames = flex_wp[1, :]\n",
        "    else:\n",
        "        raise ValueError(f\"Unexpected flex_wp shape: {flex_wp.shape}\")\n",
        "\n",
        "    fig.add_trace(\n",
        "        go.Scattergl(\n",
        "            x=f2_frames,\n",
        "            y=f1_frames,\n",
        "            mode=\"lines\",\n",
        "            name=\"Global FlexDTW\",\n",
        "            line=dict(width=4, color=\"rgba(0,0,0,1)\")\n",
        "        )\n",
        "    )\n",
        "    if xy is not None:\n",
        "        xy_arr = np.asarray(xy)\n",
        "\n",
        "        if xy_arr.ndim != 2 or xy_arr.shape[1] != 2:\n",
        "            raise ValueError(f\"xy must have shape (N,2), got {xy_arr.shape}\")\n",
        "\n",
        "        xy_frames = xy\n",
        "\n",
        "        fig.add_trace(\n",
        "            go.Scattergl(\n",
        "                x=xy_frames[:, 1],   # F2 frames\n",
        "                y=xy_frames[:, 0],   # F1 frames\n",
        "                mode=\"lines\",\n",
        "                name=\"Ground Truth\",\n",
        "                line=dict(width=4, dash=\"dash\", color=\"rgba(0,200,0,0.9)\")\n",
        "            )\n",
        "        )\n",
        "    x_lo, x_hi = -0.5, L2 - 0.5\n",
        "    y_lo, y_hi = -0.5, L1 - 0.5\n",
        "\n",
        "    fig.update_layout(\n",
        "        title=\"Global FlexDTW vs ParFlex (with chunk-S spiky background)\",\n",
        "        xaxis_title=f\"F2 frames (0 … {L2-1})\",\n",
        "        yaxis_title=f\"F1 frames (0 … {L1-1})\",\n",
        "        legend=dict(x=0.01, y=0.99),\n",
        "        width=fig_width,\n",
        "        height=fig_height,\n",
        "        plot_bgcolor=\"white\",\n",
        "        paper_bgcolor=\"white\",\n",
        "    )\n",
        "\n",
        "    fig.update_xaxes(range=[x_lo, x_hi], showgrid=False)\n",
        "    fig.update_yaxes(range=[y_lo, y_hi], showgrid=False)\n",
        "    shapes = []\n",
        "    for x in range(L_div, L2, L_div):\n",
        "        shapes.append(dict(\n",
        "            type=\"line\",\n",
        "            x0=x, x1=x,\n",
        "            y0=y_lo, y1=y_hi,\n",
        "            line=dict(width=1, dash=\"dot\")\n",
        "        ))\n",
        "    for y in range(L_div, L1, L_div):\n",
        "        shapes.append(dict(\n",
        "            type=\"line\",\n",
        "            x0=x_lo, x1=x_hi,\n",
        "            y0=y, y1=y,\n",
        "            line=dict(width=1, dash=\"dot\")\n",
        "        ))\n",
        "    fig.update_layout(shapes=shapes)\n",
        "    fig.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Chunking and coordinate helpers\n",
        "\n",
        "Split cost matrix into overlapping chunks; run FlexDTW per chunk. Helpers map edge indices to local/global coords and decode FlexDTW start encoding (S)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        " \n",
        "def chunk_flexdtw(C, L, steps=None, weights=None, buffer=1):\n",
        "    \"\"\"\n",
        "    Tile cost matrix C into overlapping L×L chunks (1-cell overlap), run FlexDTW on each.\n",
        "    Returns chunks_dict keyed by (i, j) with 'C', 'D', 'S', 'B', 'bounds', 'hop', 'shape', etc.\n",
        "    \"\"\"\n",
        "    import math\n",
        "    \n",
        "    if steps is None:\n",
        "        steps = [(1,1), (1,2), (2,1)]\n",
        "    if weights is None:\n",
        "        weights = [2, 3, 3]\n",
        "    \n",
        "    L1, L2 = C.shape\n",
        "    hop = L - 1\n",
        "    \n",
        "    n_chunks_1 = math.ceil((L1 - 1) / hop)\n",
        "    n_chunks_2 = math.ceil((L2 - 1) / hop)\n",
        "    chunks_dict = {}\n",
        "    for i in range(n_chunks_1):\n",
        "        for j in range(n_chunks_2):\n",
        "            start_1, start_2 = i * hop, j * hop\n",
        "            end_1, end_2 = start_1 + L, start_2 + L\n",
        "            if end_1 > L1:\n",
        "                end_1 = L1\n",
        "            \n",
        "            if end_2 > L2:\n",
        "                end_2 = L2\n",
        "            C_chunk = C[int(start_1):int(end_1), int(start_2):int(end_2)]\n",
        "            try:\n",
        "                import FlexDTW\n",
        "                best_cost, wp, D, P, B, debug = FlexDTW.flexdtw(\n",
        "                    C_chunk, \n",
        "                    steps=steps, \n",
        "                    weights=weights, \n",
        "                    buffer=1\n",
        "                )\n",
        "            except ImportError:\n",
        "                best_cost = 0\n",
        "                wp = []\n",
        "                D = np.zeros_like(C_chunk)\n",
        "                P = np.zeros_like(C_chunk)\n",
        "                B = np.zeros_like(C_chunk)\n",
        "                debug = {}\n",
        "            actual_hop_1 = hop if end_1 < L1 else (L1 - start_1)\n",
        "            actual_hop_2 = hop if end_2 < L2 else (L2 - start_2)\n",
        "            \n",
        "            chunks_dict[(i, j)] = {\n",
        "                'C': C_chunk,\n",
        "                'D': D,\n",
        "                'S': P,\n",
        "                'B': B,\n",
        "                'debug': debug,\n",
        "                'best_cost': best_cost,\n",
        "                'wp': wp,\n",
        "                'bounds': (start_1, end_1, start_2, end_2),\n",
        "                'hop': (actual_hop_1, actual_hop_2),\n",
        "                'shape': C_chunk.shape\n",
        "            }\n",
        "    return chunks_dict, L, n_chunks_1, n_chunks_2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def edge_index_to_local_coords(edge_type, position, chunk_shape):\n",
        "    \"\"\"Edge 0 = top → (last_row, position); edge 1 = right → (position, last_col).\"\"\"\n",
        "    if edge_type == 0:\n",
        "        return chunk_shape[0] - 1, position\n",
        "    return position, chunk_shape[1] - 1\n",
        "\n",
        "\n",
        "def local_to_global_coords(chunk_i, chunk_j, local_row, local_col, chunks_dict):\n",
        "    \"\"\"Map (local_row, local_col) in chunk (i, j) to global (row, col).\"\"\"\n",
        "    start_1, _, start_2, _ = chunks_dict[(chunk_i, chunk_j)]['bounds']\n",
        "    return start_1 + local_row, start_2 + local_col\n",
        "\n",
        "\n",
        "def decode_path_start_from_S(S_single, end_row, end_col):\n",
        "    \"\"\"From FlexDTW S encoding at (end_row, end_col): S>0 → start (0, S); S<0 → start (-S, 0); else (0,0).\"\"\"\n",
        "    val = S_single[end_row, end_col]\n",
        "    if val > 0:\n",
        "        return 0, int(val)\n",
        "    if val < 0:\n",
        "        return abs(int(val)), 0\n",
        "    return 0, 0\n",
        "\n",
        "\n",
        "def _on_bottom_edge(start_row, start_col, chunk_shape):\n",
        "    return start_row == 0\n",
        "\n",
        "\n",
        "def _on_left_edge(start_row, start_col, chunk_shape):\n",
        "    return start_col == 0\n",
        "\n",
        "\n",
        "def global_to_prev_chunk_edge(global_row, global_col, prev_chunk_i, prev_chunk_j, chunks_dict, L):\n",
        "    \"\"\"Map global (row, col) to (edge_type, position) on the previous chunk's top or right edge.\"\"\"\n",
        "    start_1, _, start_2, _ = chunks_dict[(prev_chunk_i, prev_chunk_j)]['bounds']\n",
        "    local_row = global_row - start_1\n",
        "    local_col = global_col - start_2\n",
        "    prev_chunk_shape = chunks_dict[(prev_chunk_i, prev_chunk_j)]['D'].shape\n",
        "    if local_row == prev_chunk_shape[0] - 1:\n",
        "        return 0, local_col\n",
        "    if local_col == prev_chunk_shape[1] - 1:\n",
        "        return 1, local_row\n",
        "    raise ValueError(f\"({local_row}, {local_col}) not on edge of previous chunk\")\n",
        "\n",
        "\n",
        "def initialize_chunks(chunks_dict, num_chunks_1, num_chunks_2, L):\n",
        "    \"\"\"\n",
        "    Initialize D_chunks and L_chunks for the first row and first column.\n",
        "    Uses flexible data structure to accommodate non-square boundary chunks.\n",
        "    Ensures edge continuity between adjacent chunks.\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    chunks_dict : dict\n",
        "        Dictionary containing chunk data (including 'hop' for each chunk)\n",
        "    num_chunks_1, num_chunks_2 : int, int\n",
        "        Number of chunks in each dimension\n",
        "    L : int\n",
        "        Chunk size\n",
        "        \n",
        "    Returns:\n",
        "    --------\n",
        "    D_chunks, L_chunks : list of list of dicts of lists\n",
        "        Indexed as [chunk_row][chunk_col][edge_type][position]\n",
        "        Where position is a Python list that can vary in length\n",
        "    \"\"\"\n",
        "    # Initialize as nested lists with dicts for edge types\n",
        "    D_chunks = [[{0: [], 1: []} for _ in range(num_chunks_2)] for _ in range(num_chunks_1)]\n",
        "    L_chunks = [[{0: [], 1: []} for _ in range(num_chunks_2)] for _ in range(num_chunks_1)]\n",
        "    \n",
        "    # Helper function to get actual edge length for a chunk\n",
        "    def _edge_length(chunk_shape, edge_type):\n",
        "        \"\"\"Returns the actual length of an edge for a given chunk shape.\"\"\"\n",
        "        if edge_type == 0:  # top edge\n",
        "            return chunk_shape[1]  # width\n",
        "        else:  # right edge (edge_type == 1)\n",
        "            return chunk_shape[0]  # height\n",
        "    \n",
        "    # Initialize chunk (0, 0)\n",
        "    D_single_00 = chunks_dict[(0, 0)]['D']\n",
        "    S_single_00 = chunks_dict[(0, 0)]['S']\n",
        "    \n",
        "    for edge_type in range(2):\n",
        "        edge_len = _edge_length(D_single_00.shape, edge_type)\n",
        "        # Initialize lists with inf values\n",
        "        D_chunks[0][0][edge_type] = [np.inf] * edge_len\n",
        "        L_chunks[0][0][edge_type] = [np.inf] * edge_len\n",
        "        \n",
        "        for position in range(edge_len):\n",
        "            local_row, local_col = edge_index_to_local_coords(edge_type, position, D_single_00.shape)\n",
        "            \n",
        "            if local_row < D_single_00.shape[0] and local_col < D_single_00.shape[1]:\n",
        "                start_row, start_col = decode_path_start_from_S(S_single_00, local_row, local_col)\n",
        "\n",
        "                if _on_bottom_edge(start_row, start_col, D_single_00.shape) or \\\n",
        "                   _on_left_edge(start_row, start_col, D_single_00.shape):\n",
        "                    D_chunks[0][0][edge_type][position] = D_single_00[local_row, local_col]\n",
        "                    path_length = abs(local_row - start_row) + abs(local_col - start_col)\n",
        "                    L_chunks[0][0][edge_type][position] = path_length\n",
        "    \n",
        "    # ==================================================================================\n",
        "    # CASE 1: Initialize first row - chunks (0, j) for j = 1, 2, ...\n",
        "    # ==================================================================================\n",
        "    for j in range(1, num_chunks_2):\n",
        "        if (0, j) not in chunks_dict:\n",
        "            continue\n",
        "            \n",
        "        D_single = chunks_dict[(0, j)]['D']\n",
        "        S_single = chunks_dict[(0, j)]['S'] \n",
        "        C_chunk = chunks_dict[(0, j)]['C'] if 'C' in chunks_dict[(0, j)] else None\n",
        "        \n",
        "        # Edge continuity: 0th index on top edge should equal previous chunk's last index on top edge\n",
        "        D_chunks[0][j][0] = [D_chunks[0][j-1][0][-1]] + [np.inf] * (_edge_length(D_single.shape, 0) - 1)\n",
        "        L_chunks[0][j][0] = [L_chunks[0][j-1][0][-1]] + [np.inf] * (_edge_length(D_single.shape, 0) - 1)\n",
        "        \n",
        "        # Initialize right edge\n",
        "        edge_len_right = _edge_length(D_single.shape, 1)\n",
        "        D_chunks[0][j][1] = [np.inf] * edge_len_right\n",
        "        L_chunks[0][j][1] = [np.inf] * edge_len_right\n",
        "        \n",
        "        for edge_type in range(2):\n",
        "            edge_len = _edge_length(D_single.shape, edge_type)\n",
        "            \n",
        "            for position in range(1,edge_len):\n",
        "                # Skip position 0 for edge_type 0 (top edge) - already set by continuity\n",
        "                if edge_type == 0 and position == 0:\n",
        "                    continue\n",
        "                    \n",
        "                local_row, local_col = edge_index_to_local_coords(edge_type, position, D_single.shape)\n",
        "                \n",
        "                if local_row >= D_single.shape[0] or local_col >= D_single.shape[1]:\n",
        "                    continue\n",
        "\n",
        "                start_row, start_col = decode_path_start_from_S(S_single, local_row, local_col)\n",
        "\n",
        "                # Case 1: Valid start on bottom edge\n",
        "                if _on_bottom_edge(start_row, start_col, D_single.shape):\n",
        "                    D_chunks[0][j][edge_type][position] = D_single[local_row, local_col]\n",
        "                    path_length = abs(local_row - start_row) + abs(local_col - start_col)\n",
        "                    L_chunks[0][j][edge_type][position] = path_length\n",
        "                \n",
        "                # Case 2: Start on left edge - need cost from previous chunk\n",
        "                elif _on_left_edge(start_row, start_col, D_single.shape):\n",
        "                    # Get global coordinates of starting point\n",
        "                    global_start_row, global_start_col = local_to_global_coords(\n",
        "                        0, j, start_row, start_col, chunks_dict\n",
        "                    )\n",
        "                    \n",
        "                    # Map to previous chunk (0, j-1)\n",
        "                    prev_edge_type, prev_position = global_to_prev_chunk_edge(\n",
        "                        global_start_row, global_start_col, 0, j - 1, chunks_dict, L\n",
        "                    )\n",
        "                    \n",
        "                    # Check if prev_position is within bounds of previous chunk's edge\n",
        "                    prev_edge_len = len(D_chunks[0][j-1][prev_edge_type])\n",
        "                    if prev_position >= prev_edge_len:\n",
        "                        continue\n",
        "                    \n",
        "                    # Get cost from previous chunk\n",
        "                    prev_cost = D_chunks[0][j-1][prev_edge_type][prev_position]\n",
        "                    \n",
        "                    if np.isfinite(prev_cost):  # Only if valid path exists\n",
        "                        # Subtract overlapping cell cost from CURRENT chunk to avoid double counting\n",
        "                        overlap_cost = C_chunk[start_row, 0] if C_chunk is not None else 0\n",
        "                        \n",
        "                        D_chunks[0][j][edge_type][position] = D_single[local_row, local_col] + prev_cost - overlap_cost \n",
        "                        # Path length includes previous chunk\n",
        "                        prev_length = L_chunks[0][j-1][prev_edge_type][prev_position]\n",
        "                        curr_length = abs(local_row - start_row) + abs(local_col - start_col)\n",
        "                        L_chunks[0][j][edge_type][position] = prev_length + curr_length\n",
        "    \n",
        "    # ==================================================================================\n",
        "    # CASE 2: Initialize first column - chunks (i, 0) for i = 1, 2, ...\n",
        "    # ==================================================================================\n",
        "    for i in range(1, num_chunks_1):\n",
        "        if (i, 0) not in chunks_dict:\n",
        "            continue\n",
        "            \n",
        "        D_single = chunks_dict[(i, 0)]['D']\n",
        "        S_single = chunks_dict[(i, 0)]['S']\n",
        "        C_chunk = chunks_dict[(i, 0)]['C'] if 'C' in chunks_dict[(i, 0)] else None\n",
        "        \n",
        "        # Edge continuity: 0th index on right edge should equal previous chunk's last index on right edge\n",
        "        D_chunks[i][0][1] = [D_chunks[i-1][0][1][-1]] + [np.inf] * (_edge_length(D_single.shape, 1) - 1)\n",
        "        L_chunks[i][0][1] = [L_chunks[i-1][0][1][-1]] + [np.inf] * (_edge_length(D_single.shape, 1) - 1)\n",
        "        \n",
        "        # Initialize top edge\n",
        "        edge_len_top = _edge_length(D_single.shape, 0)\n",
        "        D_chunks[i][0][0] = [np.inf] * edge_len_top\n",
        "        L_chunks[i][0][0] = [np.inf] * edge_len_top\n",
        "        \n",
        "        for edge_type in range(2):\n",
        "            edge_len = _edge_length(D_single.shape, edge_type)\n",
        "            \n",
        "            for position in range(1,edge_len):\n",
        "                # Skip position 0 for edge_type 1 (right edge) - already set by continuity\n",
        "                if edge_type == 1 and position == 0:\n",
        "                    continue\n",
        "                    \n",
        "                local_row, local_col = edge_index_to_local_coords(edge_type, position, D_single.shape)\n",
        "                \n",
        "                if local_row >= D_single.shape[0] or local_col >= D_single.shape[1]:\n",
        "                    continue\n",
        "\n",
        "                start_row, start_col = decode_path_start_from_S(S_single, local_row, local_col)\n",
        "\n",
        "                # Case 1: Valid start on left edge\n",
        "                if _on_left_edge(start_row, start_col, D_single.shape):\n",
        "                    D_chunks[i][0][edge_type][position] = D_single[local_row, local_col]\n",
        "                    path_length = abs(local_row - start_row) + abs(local_col - start_col)\n",
        "                    L_chunks[i][0][edge_type][position] = path_length\n",
        "                \n",
        "                # Case 2: Start on bottom edge - need cost from previous chunk\n",
        "                elif _on_bottom_edge(start_row, start_col, D_single.shape):\n",
        "                    # Get global coordinates of starting point\n",
        "                    global_start_row, global_start_col = local_to_global_coords(\n",
        "                        i, 0, start_row, start_col, chunks_dict\n",
        "                    )\n",
        "                    \n",
        "                    # Map to previous chunk (i-1, 0)\n",
        "                    prev_edge_type, prev_position = global_to_prev_chunk_edge(\n",
        "                        global_start_row, global_start_col, i - 1, 0, chunks_dict, L\n",
        "                    )\n",
        "                    \n",
        "                    # Check if prev_position is within bounds of previous chunk's edge\n",
        "                    prev_edge_len = len(D_chunks[i-1][0][prev_edge_type])\n",
        "                    if prev_position >= prev_edge_len:\n",
        "                        continue\n",
        "                    \n",
        "                    # Get cost from previous chunk\n",
        "                    prev_cost = D_chunks[i-1][0][prev_edge_type][prev_position]\n",
        "                    \n",
        "                    if np.isfinite(prev_cost):  # Only if valid path exists\n",
        "                        # Subtract overlapping cell cost from CURRENT chunk\n",
        "                        overlap_cost = C_chunk[0, start_col] if C_chunk is not None else 0\n",
        "                        \n",
        "                        D_chunks[i][0][edge_type][position] = D_single[local_row, local_col] + prev_cost - overlap_cost\n",
        "                        \n",
        "                        # Path length includes previous chunk\n",
        "                        prev_length = L_chunks[i-1][0][prev_edge_type][prev_position]\n",
        "                        curr_length = abs(local_row - start_row) + abs(local_col - start_col)\n",
        "                        L_chunks[i][0][edge_type][position] = prev_length + curr_length\n",
        "    \n",
        "    return D_chunks, L_chunks\n",
        "\n",
        "\n",
        "def dp_fill_chunks(chunks_dict, D_chunks, L_chunks, num_chunks_1, num_chunks_2, L):\n",
        "    \"\"\"\n",
        "    Fill in D_chunks and L_chunks for all interior chunks using dynamic programming.\n",
        "    Uses flexible hop sizes from chunks_dict.\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    chunks_dict : dict\n",
        "        Dictionary containing chunk data (including flexible 'hop' per chunk)\n",
        "    D_chunks, L_chunks : list of list of dicts of lists\n",
        "        Chunk-level cost and length tensors (partially filled)\n",
        "    num_chunks_1, num_chunks_2 : int, int\n",
        "        Number of chunks in each dimension\n",
        "    L : int\n",
        "        Standard chunk size (for reference)\n",
        "    \"\"\"\n",
        "    def _edge_length(chunk_shape, edge_type):\n",
        "        return chunk_shape[1] if edge_type == 0 else chunk_shape[0]\n",
        "    for i in range(num_chunks_1):\n",
        "        for j in range(num_chunks_2):\n",
        "            # Skip first row and first column (already initialized)\n",
        "            if i == 0 or j == 0:\n",
        "                continue\n",
        "            \n",
        "            D_single = chunks_dict[(i, j)]['D']\n",
        "            S_single = chunks_dict[(i, j)]['S']\n",
        "            C_chunk = chunks_dict[(i, j)]['C'] if 'C' in chunks_dict[(i, j)] else None\n",
        "            \n",
        "            for edge_type in range(2):\n",
        "                edge_len = _edge_length(D_single.shape, edge_type)\n",
        "                # Initialize lists for this chunk if not already done\n",
        "                D_chunks[i][j][edge_type] = [np.inf] * edge_len\n",
        "                L_chunks[i][j][edge_type] = [np.inf] * edge_len\n",
        "                \n",
        "                for position in range(edge_len):\n",
        "                    \n",
        "                    # Special case for position 0: try to inherit from adjacent chunk\n",
        "                    if position == 0:\n",
        "                        inherited = False\n",
        "                        \n",
        "                        # For top edge at position 0: use left chunk's top edge rightmost point\n",
        "                        if edge_type == 0 and j > 0:\n",
        "                            left_edge_len = len(D_chunks[i][j-1][0])\n",
        "                            if left_edge_len > 0:\n",
        "                                rightmost_pos = left_edge_len - 1\n",
        "                                left_cost = D_chunks[i][j-1][0][rightmost_pos]\n",
        "                                left_length = L_chunks[i][j-1][0][rightmost_pos]\n",
        "                                \n",
        "                                if np.isfinite(left_cost):\n",
        "                                    D_chunks[i][j][edge_type][position] = left_cost\n",
        "                                    L_chunks[i][j][edge_type][position] = left_length\n",
        "                                    inherited = True\n",
        "                        \n",
        "                        # For right edge at position 0: use top chunk's right edge bottommost point\n",
        "                        elif edge_type == 1 and i > 0:\n",
        "                            top_edge_len = len(D_chunks[i-1][j][1])\n",
        "                            if top_edge_len > 0:\n",
        "                                bottommost_pos = top_edge_len - 1\n",
        "                                top_cost = D_chunks[i-1][j][1][bottommost_pos]\n",
        "                                top_length = L_chunks[i-1][j][1][bottommost_pos]\n",
        "                                \n",
        "                                if np.isfinite(top_cost):\n",
        "                                    D_chunks[i][j][edge_type][position] = top_cost\n",
        "                                    L_chunks[i][j][edge_type][position] = top_length\n",
        "                                    inherited = True\n",
        "                        \n",
        "                        if inherited:\n",
        "                            continue\n",
        "                    local_row, local_col = edge_index_to_local_coords(edge_type, position, D_single.shape)\n",
        "                    \n",
        "                    if local_row >= D_single.shape[0] or local_col >= D_single.shape[1]:\n",
        "                        continue\n",
        "\n",
        "                    # Get starting point for this path\n",
        "                    start_row, start_col = decode_path_start_from_S(S_single, local_row, local_col)\n",
        "\n",
        "                    # Determine which previous chunk this path came from\n",
        "                    if _on_bottom_edge(start_row, start_col, D_single.shape):\n",
        "                        # Path came from chunk above (i-1, j)\n",
        "                        prev_i, prev_j = i - 1, j\n",
        "                    elif _on_left_edge(start_row, start_col, D_single.shape):\n",
        "                        # Path came from chunk to the left (i, j-1)\n",
        "                        prev_i, prev_j = i, j - 1\n",
        "                    else:\n",
        "                        # Path started within this chunk\n",
        "                        D_chunks[i][j][edge_type][position] = D_single[local_row, local_col]\n",
        "                        path_length = abs(local_row - start_row) + abs(local_col - start_col)\n",
        "                        L_chunks[i][j][edge_type][position] = path_length\n",
        "                        continue\n",
        "                    \n",
        "                    # Get global coordinates of starting point\n",
        "                    global_start_row, global_start_col = local_to_global_coords(\n",
        "                        i, j, start_row, start_col, chunks_dict\n",
        "                    )\n",
        "                    \n",
        "                    # Map to edge position in previous chunk\n",
        "                    prev_edge_type, prev_position = global_to_prev_chunk_edge(\n",
        "                        global_start_row, global_start_col, prev_i, prev_j, chunks_dict, L\n",
        "                    )\n",
        "                    \n",
        "                    # Check if prev_position is within bounds of previous chunk's edge\n",
        "                    prev_edge_len = len(D_chunks[prev_i][prev_j][prev_edge_type])\n",
        "                    if prev_position >= prev_edge_len:\n",
        "                        continue\n",
        "                    \n",
        "                    # Get accumulated cost and length from previous chunk\n",
        "                    prev_cost = D_chunks[prev_i][prev_j][prev_edge_type][prev_position]\n",
        "                    prev_length = L_chunks[prev_i][prev_j][prev_edge_type][prev_position]\n",
        "                    \n",
        "                    # Only proceed if valid path exists in previous chunk\n",
        "                    if not np.isfinite(prev_cost):\n",
        "                        continue\n",
        "                    \n",
        "                    # Current chunk contribution (subtract first cell to avoid double counting)\n",
        "                    if C_chunk is not None:\n",
        "                        first_cell_cost = C_chunk[start_row, start_col]\n",
        "                    else:\n",
        "                        first_cell_cost = 0\n",
        "                    \n",
        "                    curr_cost_contribution = D_single[local_row, local_col] - first_cell_cost\n",
        "                    curr_length = abs(local_row - start_row) + abs(local_col - start_col)\n",
        "                    \n",
        "                    # Propagate forward\n",
        "                    \n",
        "                    D_chunks[i][j][edge_type][position] = prev_cost + curr_cost_contribution\n",
        "                    # if position%4000==0:\n",
        "                    L_chunks[i][j][edge_type][position] = prev_length + curr_length\n",
        "    \n",
        "    return D_chunks, L_chunks\n",
        "def chunked_flexdtw(chunks_dict, L, num_chunks_1, num_chunks_2, buffer_param=0.1):\n",
        "    \"\"\"Propagate cost/length on chunk edges: init first row/col, then DP fill. Returns (D_chunks, L_chunks).\"\"\"\n",
        "    D_chunks, L_chunks = initialize_chunks(chunks_dict, num_chunks_1, num_chunks_2, L) \n",
        "    \n",
        "    D_chunks, L_chunks = dp_fill_chunks(chunks_dict, D_chunks, L_chunks, \n",
        "                                        num_chunks_1, num_chunks_2, L)\n",
        "    \n",
        "    return D_chunks, L_chunks\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Tiled result and Stage 2\n",
        "\n",
        "Convert chunk dict to tiled format for plotting; then run Stage 2 backtrace (best path from chunk edges)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def convert_chunks_to_tiled_result(chunks_dict, L, n_chunks_1, n_chunks_2, C, stage1_params=None):\n",
        "    \"\"\"Convert chunk_flexdtw output to tiled format for plot_parflex_with_chunk_S_background and Stage 2.\"\"\"\n",
        "    L1, L2 = C.shape\n",
        "    hop = L - 1  # Your code uses 1-frame overlap\n",
        "    \n",
        "    # Convert chunks dictionary to list of block dicts\n",
        "    blocks = []\n",
        "    \n",
        "    for (i, j), chunk_data in chunks_dict.items():\n",
        "        # Extract bounds\n",
        "        start_1, end_1, start_2, end_2 = chunk_data['bounds']\n",
        "        rows, cols = chunk_data['shape']\n",
        "        \n",
        "        # Get the warping path (ensure it's in the right format)\n",
        "        wp_local = np.array(chunk_data['wp'])\n",
        "        if wp_local.size == 0:\n",
        "            \n",
        "            continue\n",
        "            \n",
        "        # Ensure wp_local is (N, 2)\n",
        "        if wp_local.ndim == 2 and wp_local.shape[0] == 2:\n",
        "            wp_local = wp_local.T\n",
        "        \n",
        "        # Calculate raw cost and path length\n",
        "        C_chunk = chunk_data['C']\n",
        "        raw_cost_blk = float(C_chunk[wp_local[:, 0], wp_local[:, 1]].sum())\n",
        "        path_len_blk = int(np.abs(np.diff(wp_local, axis=0)).sum(axis=1).sum() + 1)\n",
        "        \n",
        "        # Map local path to global coordinates\n",
        "        wp_global = np.column_stack([\n",
        "            wp_local[:, 0] + start_1,\n",
        "            wp_local[:, 1] + start_2\n",
        "        ])\n",
        "        \n",
        "        block_dict = {\n",
        "            'bi': i,\n",
        "            'bj': j,\n",
        "            'rows': (int(start_1), int(end_1)),\n",
        "            'cols': (int(start_2), int(end_2)),\n",
        "            'Ck_shape': (rows, cols),\n",
        "            'best_cost': float(chunk_data['best_cost']),\n",
        "            'wp_global': wp_global,\n",
        "            'wp_local': wp_local.copy(),\n",
        "            'raw_cost': raw_cost_blk,\n",
        "            'path_len': path_len_blk,\n",
        "            'D_single': chunk_data['D'],\n",
        "            'B_single': chunk_data['B'],\n",
        "            'S_single': chunk_data['S']  # Your 'S' becomes 'S_single'\n",
        "        }\n",
        "        \n",
        "        blocks.append(block_dict)\n",
        "    \n",
        "    # Default stage1 parameters if not provided\n",
        "    if stage1_params is None:\n",
        "        stage1_params = {\n",
        "            'steps': np.array([[1, 1], [1, 2], [2, 1]], dtype=int),\n",
        "            'weights': np.array([1.5, 3.0, 3.0], dtype=float),\n",
        "            'buffer': 1.0\n",
        "        }\n",
        "    \n",
        "    # Build the tiled_result dictionary\n",
        "    tiled_result = {\n",
        "        'C_shape': (L1, L2),\n",
        "        'L_block': L,\n",
        "        'hop': hop,\n",
        "        'n_row': n_chunks_1,\n",
        "        'n_col': n_chunks_2,\n",
        "        'blocks': blocks,\n",
        "        'C': C,\n",
        "        'stage1_params': stage1_params\n",
        "    }\n",
        "    \n",
        "    return tiled_result\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def stage_2_backtrace_compatible(tiled_result, all_blocks, D_chunks, L_chunks, L1, L2,\n",
        "                                  L_block, buffer_stage2=200, top_k=1):\n",
        "    \"\"\"Scan top/right edges for best normalized cost; backtrace and stitch path across chunks. Returns dict with stitched_wp, best_cost, paths_per_segment, etc.\"\"\"\n",
        "    \n",
        "    INF = 1e9\n",
        "    n_row = len(D_chunks)\n",
        "    n_col = len(D_chunks[0]) if n_row > 0 else 0\n",
        "    \n",
        "    def edge_to_local(edge, idx, rows, cols):\n",
        "        \"\"\"Convert edge representation to local coordinates.\"\"\"\n",
        "        if edge == 0:  # top\n",
        "            return rows - 1, idx\n",
        "        else:  # right\n",
        "            return idx, cols - 1\n",
        "    \n",
        "    def backtrace_within_chunk(B_single, steps, start_r, start_c, end_r, end_c, \n",
        "                                global_r_offset, global_c_offset):\n",
        "        \"\"\"\n",
        "        Backtrace from (end_r, end_c) back to (start_r, start_c) within a chunk.\n",
        "        Returns path in GLOBAL coordinates, in END → START order.\n",
        "        \"\"\"\n",
        "        path = []\n",
        "        r, c = end_r, end_c\n",
        "        max_iters = B_single.shape[0] * B_single.shape[1]\n",
        "        iters = 0\n",
        "\n",
        "        while iters < max_iters:\n",
        "            path.append((r + global_r_offset, c + global_c_offset))\n",
        "\n",
        "            if r == start_r and c == start_c:\n",
        "                if len(path) == 0 or path[-1] != (start_r + global_r_offset, start_c + global_c_offset):\n",
        "                    path.append((start_r + global_r_offset, start_c + global_c_offset))\n",
        "                break\n",
        "\n",
        "            step_idx = int(B_single[r, c])\n",
        "            if step_idx < 0 or step_idx >= len(steps):\n",
        "                if (r != start_r or c != start_c):\n",
        "                    path.append((start_r + global_r_offset, start_c + global_c_offset))\n",
        "                break\n",
        "\n",
        "            dr, dc = steps[step_idx]\n",
        "            prev_r = r - dr\n",
        "            prev_c = c - dc\n",
        "\n",
        "            if (prev_r < 0 or prev_c < 0 or \n",
        "                prev_r >= B_single.shape[0] or prev_c >= B_single.shape[1]):\n",
        "                if (r != start_r or c != start_c):\n",
        "                    path.append((start_r + global_r_offset, start_c + global_c_offset))\n",
        "                break\n",
        "\n",
        "            r, c = prev_r, prev_c\n",
        "            iters += 1\n",
        "\n",
        "        if iters >= max_iters:\n",
        "            \n",
        "            if (r != start_r or c != start_c):\n",
        "                path.append((start_r + global_r_offset, start_c + global_c_offset))\n",
        "\n",
        "        return path\n",
        "\n",
        "    def backtrace_and_stitch(start_i, start_j, start_edge, start_idx):\n",
        "        \"\"\"\n",
        "        Backtrack from a specific edge endpoint and stitch across chunks.\n",
        "        Returns the GLOBAL path in START → END order.\n",
        "        \"\"\"\n",
        "        path = []\n",
        "        cur_i, cur_j, cur_edge, cur_idx = start_i, start_j, start_edge, start_idx\n",
        "        steps = tiled_result['stage1_params']['steps']\n",
        "        visited_chunks = set()\n",
        "        stop_reason = None\n",
        "        iteration = 0\n",
        "\n",
        "        while True:\n",
        "            iteration += 1\n",
        "            chunk_key = (cur_i, cur_j, cur_edge, cur_idx)\n",
        "\n",
        "            if chunk_key in visited_chunks:\n",
        "                stop_reason = f\"loop at chunk {chunk_key}\"\n",
        "                break\n",
        "            visited_chunks.add(chunk_key)\n",
        "\n",
        "            if (cur_i, cur_j) not in all_blocks:\n",
        "                stop_reason = f\"missing chunk ({cur_i},{cur_j})\"\n",
        "                break\n",
        "\n",
        "            b = all_blocks[(cur_i, cur_j)]\n",
        "            rows, cols = b['shape']  # Changed from 'Ck_shape'\n",
        "            r_start, r_end, c_start, c_end = b['bounds']  # Changed from separate 'rows' and 'cols'\n",
        "\n",
        "            end_r, end_c = edge_to_local(cur_edge, cur_idx, rows, cols)\n",
        "            S_val = b['S'][end_r, end_c]  # Changed from 'S_single'\n",
        "\n",
        "            if S_val >= 0:\n",
        "                start_r = 0\n",
        "                start_c = int(S_val)\n",
        "            else:\n",
        "                start_r = int(-S_val)\n",
        "                start_c = 0\n",
        "\n",
        "            chunk_path = backtrace_within_chunk(\n",
        "                b['B'], steps, start_r, start_c, end_r, end_c, r_start, c_start\n",
        "            )  # Changed from 'B_single' to 'B'\n",
        "\n",
        "            for pt in chunk_path:\n",
        "                if not path or path[-1] != pt:\n",
        "                    path.append(pt)\n",
        "\n",
        "            g_start_row = r_start + start_r\n",
        "            g_start_col = c_start + start_c\n",
        "\n",
        "            if g_start_row == 0:\n",
        "                stop_reason = f\"hit bottom edge at global row 0, col {g_start_col}\"\n",
        "                break\n",
        "            if g_start_col == 0:\n",
        "                stop_reason = f\"hit left edge at global row {g_start_row}, col 0\"\n",
        "                break\n",
        "\n",
        "            # If we land exactly on the chunk corner (local (0,0)), we explicitly\n",
        "            # jump to the bottom-left chunk and continue from its top-edge corner.\n",
        "            # This avoids ambiguity about whether we should move \"up\" or \"left\".\n",
        "            corner_landed = (start_r == 0 and start_c == 0)\n",
        "\n",
        "            if corner_landed:\n",
        "                prev_i, prev_j = cur_i - 1, cur_j - 1\n",
        "                prev_edge = 0  # top edge\n",
        "            elif S_val >= 0:\n",
        "                prev_i, prev_j = cur_i - 1, cur_j\n",
        "                prev_edge = 0\n",
        "            else:\n",
        "                prev_i, prev_j = cur_i, cur_j - 1\n",
        "                prev_edge = 1\n",
        "             \n",
        "\n",
        "            if prev_i < 0 or prev_j < 0:\n",
        "                stop_reason = f\"corner transition out of bounds to ({prev_i},{prev_j})\"\n",
        "                break\n",
        "\n",
        "            if (prev_i, prev_j) not in all_blocks:\n",
        "                stop_reason = f\"previous chunk ({prev_i},{prev_j}) missing\"\n",
        "                break\n",
        "\n",
        "            prev_b = all_blocks[(prev_i, prev_j)]\n",
        "            prev_r_start, prev_r_end, prev_c_start, prev_c_end = prev_b['bounds']  # Changed from separate tuples\n",
        "            prev_rows, prev_cols = prev_b['shape']  # Changed from 'Ck_shape'\n",
        "\n",
        "            if corner_landed:\n",
        "                # Bottom-left chunk's top-edge corner (its top-right) touches current chunk's corner.\n",
        "                prev_idx = prev_cols - 1\n",
        "                max_prev_idx = prev_cols\n",
        "            else:\n",
        "                prev_lr = g_start_row - prev_r_start\n",
        "                prev_lc = g_start_col - prev_c_start\n",
        "\n",
        "                prev_idx = prev_lc if prev_edge == 0 else prev_lr\n",
        "                max_prev_idx = prev_cols if prev_edge == 0 else prev_rows\n",
        "\n",
        "            if prev_idx < 0 or prev_idx >= max_prev_idx:\n",
        "                stop_reason = f\"prev_idx out of bounds({prev_idx}/{max_prev_idx})\"\n",
        "                break\n",
        "\n",
        "            cur_i, cur_j, cur_edge, cur_idx = prev_i, prev_j, prev_edge, prev_idx\n",
        "\n",
        "            if iteration > 100:\n",
        "                stop_reason = f\"iteration limit ({iteration})\"\n",
        "                break\n",
        "\n",
        "        path = path[::-1]\n",
        "        return path\n",
        "\n",
        "    def global_to_chunk_edge(g_row, g_col):\n",
        "        \"\"\"\n",
        "        Given a GLOBAL (g_row, g_col) on the top or right edge of C_global,\n",
        "        find the corresponding chunk, edge, and local edge index.\n",
        "        \"\"\"\n",
        "        for (bi, bj), b in all_blocks.items():\n",
        "            r_start, r_end, c_start, c_end = b['bounds']  # Changed to unpack all 4 values\n",
        "\n",
        "            if r_start <= g_row < r_end and c_start <= g_col < c_end:\n",
        "                rows, cols = b['shape']  # Changed from 'Ck_shape'\n",
        "                local_r = g_row - r_start\n",
        "                local_c = g_col - c_start\n",
        "\n",
        "                if local_r == rows - 1:\n",
        "                    return (bi, bj, 0, local_c)\n",
        "                elif local_c == cols - 1:\n",
        "                    return (bi, bj, 1, local_r)\n",
        "        return None\n",
        "\n",
        "    top_D = np.full(L2, np.nan)\n",
        "    top_L = np.zeros(L2)\n",
        "    right_D = np.full(L1, np.nan)\n",
        "    right_L = np.zeros(L1)\n",
        "\n",
        "    best_overall_cost = float('inf')\n",
        "    best_overall_end = None\n",
        "    best_per_segment = {}\n",
        "    candidate_endpoints = []\n",
        "\n",
        "    # Scan TOP edge\n",
        "    valid_endpoints_found = 0\n",
        "    buf = int(buffer_stage2)\n",
        "\n",
        "    for g_col in range(L2):\n",
        "        g_row = L1 - 1\n",
        "       \n",
        "        if buf > 0 and g_col < buf: \n",
        "            continue\n",
        "\n",
        "        chunk_info = global_to_chunk_edge(g_row, g_col)\n",
        "        if chunk_info is None: \n",
        "            continue\n",
        "\n",
        "        chunk_i, chunk_j, edge, idx = chunk_info\n",
        "        \n",
        "        # Access D_chunks and L_chunks with flexible structure\n",
        "        if chunk_i >= len(D_chunks) or chunk_j >= len(D_chunks[chunk_i]): \n",
        "            continue\n",
        "        if edge not in D_chunks[chunk_i][chunk_j]: \n",
        "            continue\n",
        "        if idx >= len(D_chunks[chunk_i][chunk_j][edge]): \n",
        "            continue\n",
        "            \n",
        "        D_val = D_chunks[chunk_i][chunk_j][edge][idx]\n",
        "        L_val = L_chunks[chunk_i][chunk_j][edge][idx]\n",
        "         \n",
        "\n",
        "        if D_val >= INF or L_val <= 0: \n",
        "            continue\n",
        "        valid_endpoints_found += 1\n",
        "        norm_cost = D_val / L_val\n",
        "        \n",
        "\n",
        "        top_D[g_col] = D_val\n",
        "        top_L[g_col] = L_val\n",
        "        \n",
        "        if norm_cost < best_overall_cost:\n",
        "            best_overall_cost = norm_cost\n",
        "            best_overall_end = (g_row, g_col, chunk_i, chunk_j, edge, idx)\n",
        "\n",
        "        seg_idx = int(g_col // L_block)\n",
        "        key = ('top', seg_idx)\n",
        "\n",
        "        prev = best_per_segment.get(key)\n",
        "        if (prev is None) or (norm_cost < prev['norm_cost']):\n",
        "            best_per_segment[key] = {\n",
        "                'chunk_i': chunk_i,\n",
        "                'chunk_j': chunk_j,\n",
        "                'edge': edge,\n",
        "                'idx': idx,\n",
        "                'norm_cost': norm_cost,\n",
        "                'global_coord': (g_row, g_col),\n",
        "                'segment': key,\n",
        "            }\n",
        "            \n",
        "        candidate_endpoints.append({\n",
        "            'g_row': g_row,\n",
        "            'g_col': g_col,\n",
        "            'chunk_i': chunk_i,\n",
        "            'chunk_j': chunk_j,\n",
        "            'edge': edge,\n",
        "            'idx': idx,\n",
        "            'norm_cost': norm_cost\n",
        "        })\n",
        "\n",
        "    # Scan RIGHT edge\n",
        "    valid_endpoints_found = 0\n",
        "\n",
        "    for g_row in range(L1):\n",
        "        g_col = L2 - 1\n",
        "\n",
        "        if buf > 0 and g_row < buf:\n",
        "            continue\n",
        "\n",
        "        chunk_info = global_to_chunk_edge(g_row, g_col)\n",
        "        if chunk_info is None:\n",
        "            continue\n",
        "\n",
        "        chunk_i, chunk_j, edge, idx = chunk_info\n",
        "        \n",
        "        # Access with flexible structure\n",
        "        if chunk_i >= len(D_chunks) or chunk_j >= len(D_chunks[chunk_i]):\n",
        "            continue\n",
        "        if edge not in D_chunks[chunk_i][chunk_j]:\n",
        "            continue\n",
        "        if idx >= len(D_chunks[chunk_i][chunk_j][edge]):\n",
        "            continue\n",
        "            \n",
        "        D_val = D_chunks[chunk_i][chunk_j][edge][idx]\n",
        "        L_val = L_chunks[chunk_i][chunk_j][edge][idx]\n",
        "\n",
        "        valid_endpoints_found += 1\n",
        "        norm_cost = D_val / L_val\n",
        "        right_D[g_row] = D_val\n",
        "        right_L[g_row] = L_val\n",
        "        if norm_cost < best_overall_cost:\n",
        "            best_overall_cost = norm_cost\n",
        "            best_overall_end = (g_row, g_col, chunk_i, chunk_j, edge, idx)\n",
        "        seg_idx = int(g_row // L_block)\n",
        "        key = ('right', seg_idx)\n",
        "        prev = best_per_segment.get(key)\n",
        "        if (prev is None) or (norm_cost < prev['norm_cost']):\n",
        "            best_per_segment[key] = {\n",
        "                'chunk_i': chunk_i,\n",
        "                'chunk_j': chunk_j,\n",
        "                'edge': edge,\n",
        "                'idx': idx,\n",
        "                'norm_cost': norm_cost,\n",
        "                'global_coord': (g_row, g_col),\n",
        "                'segment': key,\n",
        "            }\n",
        "        candidate_endpoints.append({\n",
        "            'g_row': g_row,\n",
        "            'g_col': g_col,\n",
        "            'chunk_i': chunk_i,\n",
        "            'chunk_j': chunk_j,\n",
        "            'edge': edge,\n",
        "            'idx': idx,\n",
        "            'norm_cost': norm_cost\n",
        "        })\n",
        "\n",
        "    if not candidate_endpoints:\n",
        "        raise ValueError(\"Stage 2: No valid endpoint found on global top/right edges.\")\n",
        "\n",
        "    candidate_endpoints_sorted = sorted(candidate_endpoints, key=lambda c: c['norm_cost'])\n",
        "\n",
        "    best = candidate_endpoints_sorted[0]\n",
        "    best_overall_cost = best['norm_cost'] \n",
        "    best_overall_end = (\n",
        "        best['g_row'], best['g_col'], best['chunk_i'], \n",
        "        best['chunk_j'], best['edge'], best['idx']\n",
        "    )\n",
        "\n",
        "    g_row, g_col, best_i, best_j, best_edge, best_idx = best_overall_end\n",
        "\n",
        "    K = min(top_k, len(candidate_endpoints_sorted))\n",
        "    \n",
        "    # Compute normalized arrays\n",
        "    top_norm = np.full(L2, np.nan)\n",
        "    right_norm = np.full(L1, np.nan)\n",
        "\n",
        "    top_mask = (top_L > 0) & np.isfinite(top_D)\n",
        "    right_mask = (right_L > 0) & np.isfinite(right_D)\n",
        "\n",
        "    top_norm[top_mask] = top_D[top_mask] / top_L[top_mask]\n",
        "    right_norm[right_mask] = right_D[right_mask] / right_L[right_mask]\n",
        "\n",
        "    # Backtrace per segment\n",
        "    paths_per_segment = {}\n",
        " \n",
        "\n",
        "    for seg_key, meta in best_per_segment.items():\n",
        "        ci = meta['chunk_i']\n",
        "        cj = meta['chunk_j']\n",
        "        ce = meta['edge']\n",
        "        cidx = meta['idx']\n",
        "        norm_cost = meta['norm_cost']\n",
        "        g_row, g_col = meta['global_coord']\n",
        "\n",
        "        path = backtrace_and_stitch(ci, cj, ce, cidx)\n",
        "        path_len = len(path)\n",
        "\n",
        "        paths_per_segment[seg_key] = {\n",
        "            'endpoint': meta,\n",
        "            'path': path\n",
        "        }\n",
        "\n",
        "    # Get best overall path\n",
        "    stitched_wp = np.array([], dtype=int).reshape(0, 2)\n",
        "    if best_overall_end is not None:\n",
        "        g_row, g_col, best_i, best_j, best_edge, best_idx = best_overall_end\n",
        "        best_path = backtrace_and_stitch(best_i, best_j, best_edge, best_idx)\n",
        "        if best_path:\n",
        "            stitched_wp = np.array(best_path, dtype=int)\n",
        "\n",
        "    return {\n",
        "        'D_chunks': D_chunks,\n",
        "        'L_chunks': L_chunks,\n",
        "        'best_cost': best_overall_cost,\n",
        "        'best_end': best_overall_end,\n",
        "        'stitched_wp': stitched_wp,\n",
        "        'n_row': n_row,\n",
        "        'n_col': n_col,\n",
        "        'edge_summary': {\n",
        "            'top':   {'D': top_D,   'L': top_L,   'norm': top_norm},\n",
        "            'right': {'D': right_D, 'L': right_L, 'norm': right_norm},\n",
        "        },\n",
        "        'best_per_segment': best_per_segment,\n",
        "        'paths_per_segment': paths_per_segment,\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Sync and public API\n",
        "\n",
        "Sync overlapping edge values; then **align_system_parflex** (Stage 1) and **parflex_2a** (Stage 2). **parflex** runs both in one call."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_normalized_global_edge_cost(D_chunks, L_chunks, num_chunks_1, num_chunks_2):\n",
        "    \"\"\"\n",
        "    Plot normalized accumulated cost (Cost / Length) along the global top and right edges.\n",
        "    Traversal order: Top-Left -> Top-Right -> Bottom-Right.\n",
        "    \"\"\"\n",
        "    i_top = num_chunks_1 - 1\n",
        "    j_right = num_chunks_2 - 1\n",
        "    global_edge_data = []\n",
        "    for j in range(num_chunks_2):\n",
        "        costs = np.array(D_chunks[i_top][j][0][1:])\n",
        "        lengths = np.array(L_chunks[i_top][j][0][1:])\n",
        "        valid_indices = np.isfinite(costs) & (lengths > 0)\n",
        "        normalized_costs = np.full_like(costs, np.nan, dtype=float)\n",
        "        normalized_costs[valid_indices] = costs[valid_indices] / lengths[valid_indices]\n",
        "        for cost in normalized_costs:\n",
        "            global_edge_data.append((cost, 'Top'))\n",
        "    for i in range(num_chunks_1 - 1, -1, -1):\n",
        "        costs = np.array(D_chunks[i][j_right][1][1:])\n",
        "        lengths = np.array(L_chunks[i][j_right][1][1:])\n",
        "        valid_indices = np.isfinite(costs) & (lengths > 0)\n",
        "        normalized_costs = np.full_like(costs, np.nan, dtype=float)\n",
        "        normalized_costs[valid_indices] = costs[valid_indices] / lengths[valid_indices]\n",
        "        for cost in normalized_costs[::-1]:\n",
        "            global_edge_data.append((cost, 'Right'))\n",
        "    costs = [d[0] for d in global_edge_data]\n",
        "    edge_types = [d[1] for d in global_edge_data]\n",
        "    top_costs = [costs[i] for i, e in enumerate(edge_types) if e == \"Top\"]\n",
        "    right_costs = [costs[i] for i, e in enumerate(edge_types) if e == \"Right\"]\n",
        "    top_x = np.arange(-len(top_costs), 0)\n",
        "    right_x = np.arange(1, len(right_costs) + 1)\n",
        "    plt.figure(figsize=(15, 6))\n",
        "    plt.plot(top_x, top_costs, label='Global Top Edge', color='C0', linewidth=2)\n",
        "    plt.scatter(top_x, top_costs, color='C0', s=10)\n",
        "    plt.plot(right_x, right_costs, label='Global Right Edge', color='C3', linewidth=2)\n",
        "    plt.scatter(right_x, right_costs, color='C3', s=10)\n",
        "    plt.axvline(x=0, color='gray', linestyle='--', alpha=0.7, label='Corner (0)')\n",
        "    plt.title(\"Normalized Accumulated Cost (Cost / Length) along Global Edge\", fontsize=14)\n",
        "    plt.xlabel(f\"Global Edge Position Index (Total Points: {len(costs)})\", fontsize=12)\n",
        "    plt.ylabel(\"Normalized Cost (Accumulated Cost / Path Length)\", fontsize=12)\n",
        "    plt.legend()\n",
        "    plt.grid(True, which='both', linestyle=':', alpha=0.6)\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def sync_overlapping_positions(D_chunks, L_chunks, num_chunks_1, num_chunks_2):\n",
        "    \"\"\"Ensure 1-cell overlaps between chunks share the same D/L values.\"\"\"\n",
        "    sync_count = 0\n",
        "\n",
        "    # Horizontal overlaps: chunk[i][j] top[-1] <-> chunk[i][j+1] top[0]\n",
        "    for i in range(num_chunks_1):\n",
        "        for j in range(num_chunks_2 - 1):\n",
        "            if len(D_chunks[i][j][0]) > 0 and len(D_chunks[i][j + 1][0]) > 0:\n",
        "                last_pos = len(D_chunks[i][j][0]) - 1\n",
        "                D_left = D_chunks[i][j][0][last_pos]\n",
        "                D_right = D_chunks[i][j + 1][0][0]\n",
        "\n",
        "                if np.isfinite(D_left) and not np.isfinite(D_right):\n",
        "                    D_chunks[i][j + 1][0][0] = D_left\n",
        "                    L_chunks[i][j + 1][0][0] = L_chunks[i][j][0][last_pos]\n",
        "                    sync_count += 1\n",
        "                elif not np.isfinite(D_left) and np.isfinite(D_right):\n",
        "                    D_chunks[i][j][0][last_pos] = D_right\n",
        "                    L_chunks[i][j][0][last_pos] = L_chunks[i][j + 1][0][0]\n",
        "                    sync_count += 1\n",
        "\n",
        "    # Vertical overlaps: chunk[i][j] right[-1] <-> chunk[i+1][j] right[0]\n",
        "    for i in range(num_chunks_1 - 1):\n",
        "        for j in range(num_chunks_2):\n",
        "            if len(D_chunks[i][j][1]) > 0 and len(D_chunks[i + 1][j][1]) > 0:\n",
        "                last_pos = len(D_chunks[i][j][1]) - 1\n",
        "                D_bottom = D_chunks[i][j][1][last_pos]\n",
        "                D_top = D_chunks[i + 1][j][1][0]\n",
        "\n",
        "                if np.isfinite(D_bottom) and not np.isfinite(D_top):\n",
        "                    D_chunks[i + 1][j][1][0] = D_bottom\n",
        "                    L_chunks[i + 1][j][1][0] = L_chunks[i][j][1][last_pos]\n",
        "                    sync_count += 1\n",
        "                elif not np.isfinite(D_bottom) and np.isfinite(D_top):\n",
        "                    D_chunks[i][j][1][last_pos] = D_top\n",
        "                    L_chunks[i][j][1][last_pos] = L_chunks[i + 1][j][1][0]\n",
        "                    sync_count += 1\n",
        "\n",
        "    # Within-chunk corner: chunk[i][j] top[-1] must equal chunk[i][j] right[-1]\n",
        "    for i in range(num_chunks_1):\n",
        "        for j in range(num_chunks_2):\n",
        "            if len(D_chunks[i][j][0]) > 0 and len(D_chunks[i][j][1]) > 0:\n",
        "                D_top_corner = D_chunks[i][j][0][-1]\n",
        "                D_right_corner = D_chunks[i][j][1][-1]\n",
        "\n",
        "                if np.isfinite(D_top_corner) and not np.isfinite(D_right_corner):\n",
        "                    D_chunks[i][j][1][-1] = D_top_corner\n",
        "                    L_chunks[i][j][1][-1] = L_chunks[i][j][0][-1]\n",
        "                    sync_count += 1\n",
        "                elif not np.isfinite(D_top_corner) and np.isfinite(D_right_corner):\n",
        "                    D_chunks[i][j][0][-1] = D_right_corner\n",
        "                    L_chunks[i][j][0][-1] = L_chunks[i][j][1][-1]\n",
        "                    sync_count += 1\n",
        "                elif np.isfinite(D_top_corner) and np.isfinite(D_right_corner):\n",
        "                    if not np.isclose(D_top_corner, D_right_corner):\n",
        "                        # Prefer top corner value for determinism\n",
        "                        D_chunks[i][j][1][-1] = D_top_corner\n",
        "                        L_chunks[i][j][1][-1] = L_chunks[i][j][0][-1]\n",
        "                        sync_count += 1\n",
        "\n",
        "    if sync_count > 0:\n",
        "        print(f\"Synced {sync_count} overlapping positions\")\n",
        "\n",
        "    return D_chunks, L_chunks\n",
        "\n",
        "\n",
        "def align_system_parflex(F1, F2, steps=None, weights=None, beta=0.1, L=None):\n",
        "    \"\"\"Stage 1 only: build C, chunk with FlexDTW, return (C, tiled_result). L defaults to DEFAULT_CHUNK_LENGTH.\"\"\"\n",
        "    if L is None:\n",
        "        L = DEFAULT_CHUNK_LENGTH\n",
        "    import FlexDTW\n",
        "    C = 1 - FlexDTW.L2norm(F1).T @ FlexDTW.L2norm(F2)\n",
        "    steps = steps if steps is not None else np.array([[1, 1], [1, 2], [2, 1]])\n",
        "    weights = weights if weights is not None else np.array([1.25, 3.0, 3.0])\n",
        "    steps_arr = np.array(steps).reshape((-1, 2))\n",
        "    stage1_params = {'steps': steps_arr, 'weights': np.array(weights), 'buffer': 1.0}\n",
        "    chunks_dict, L_out, n_chunks_1, n_chunks_2 = chunk_flexdtw(C, L=L, steps=steps, weights=weights, buffer=1)\n",
        "    tiled_result = convert_chunks_to_tiled_result(\n",
        "        chunks_dict, L_out, n_chunks_1, n_chunks_2, C, stage1_params=stage1_params\n",
        "    )\n",
        "    tiled_result['chunks_dict'] = chunks_dict\n",
        "    return C, tiled_result\n",
        "\n",
        "\n",
        "def parflex_2a(tiled_result, C, beta=0.1, show_fig=False, top_k=1):\n",
        "    \"\"\"Run Parflex Stage 2: propagate costs and backtrace. Returns dict with stitched_wp, best_cost, etc.\"\"\"\n",
        "    chunks_dict = tiled_result['chunks_dict']\n",
        "    L1, L2 = C.shape\n",
        "    L = tiled_result['L_block']\n",
        "    n_chunks_1, n_chunks_2 = tiled_result['n_row'], tiled_result['n_col']\n",
        "    D_chunks, L_chunks = chunked_flexdtw(chunks_dict, L, n_chunks_1, n_chunks_2, buffer_param=1)\n",
        "    D_chunks, L_chunks = sync_overlapping_positions(D_chunks, L_chunks, n_chunks_1, n_chunks_2)\n",
        "    buffer_global = min(L1, L2) * (1 - (1 - beta) * min(L1, L2) / max(L1, L2))\n",
        "    r = stage_2_backtrace_compatible(\n",
        "        tiled_result, chunks_dict, D_chunks, L_chunks, L1, L2,\n",
        "        L_block=L, buffer_stage2=buffer_global, top_k=top_k\n",
        "    )\n",
        "    if show_fig:\n",
        "        plot_normalized_global_edge_cost(D_chunks, L_chunks, n_chunks_1, n_chunks_2)\n",
        "    return r\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def parflex(C, steps, weights, beta, L=None):\n",
        "    \"\"\"Run Parflex on cost matrix C. Returns (best_cost, wp) with wp shape (2, N). L defaults to DEFAULT_CHUNK_LENGTH.\"\"\"\n",
        "    if L is None:\n",
        "        L = DEFAULT_CHUNK_LENGTH\n",
        "    L1, L2 = C.shape\n",
        "    buffer_global = min(L1, L2) * (1 - (1 - beta) * min(L1, L2) / max(L1, L2))\n",
        "\n",
        "    steps_arr = np.array(steps).reshape((-1, 2)) if hasattr(steps, '__len__') else np.array(steps)\n",
        "    weights_arr = np.array(weights)\n",
        "    stage1_params = {'steps': steps_arr, 'weights': weights_arr, 'buffer': 1.0}\n",
        "\n",
        "    chunks_dict, L_out, n_chunks_1, n_chunks_2 = chunk_flexdtw(C, L=L, steps=steps, weights=weights, buffer=1)\n",
        "    tiled_result = convert_chunks_to_tiled_result(\n",
        "        chunks_dict, L_out, n_chunks_1, n_chunks_2, C, stage1_params=stage1_params\n",
        "    )\n",
        "\n",
        "    D_chunks, L_chunks = chunked_flexdtw(chunks_dict, L_out, n_chunks_1, n_chunks_2, buffer_param=1)\n",
        "    D_chunks, L_chunks = sync_overlapping_positions(D_chunks, L_chunks, n_chunks_1, n_chunks_2)\n",
        "\n",
        "    r = stage_2_backtrace_compatible(\n",
        "        tiled_result, chunks_dict, D_chunks, L_chunks, L1, L2,\n",
        "        L_block=L, buffer_stage2=buffer_global, top_k=1\n",
        "    )\n",
        "    wp = r[\"stitched_wp\"]\n",
        "    if wp.size > 0:\n",
        "        wp = wp.T  # (N, 2) -> (2, N)\n",
        "    else:\n",
        "        wp = np.array([[], []], dtype=np.int64)\n",
        "    return r[\"best_cost\"], wp\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        " "
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "mir",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
