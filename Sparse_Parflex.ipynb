{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Parflex – Parallel FlexDTW\n",
        "\n",
        "Chunked FlexDTW with stage-2 backtrace for global alignment. Chunk length **L** (default 4000) is set in **Parameters** below; override with `L=...` in any of the entry points.\n",
        "\n",
        "**Usage**\n",
        "- **One-shot:** `best_cost, wp = Parflex.parflex(C, steps=..., weights=..., beta=0.1, L=4000)` (same as 04 align).\n",
        "- **Two-stage (e.g. compare_flex_parflex):**  \n",
        "  `C, tiled_result = Parflex.align_system_sparse_parflex(F1, F2)` →  \n",
        "  `stage2_result = Parflex.sparse_parflex_2a(tiled_result, C, beta=0.1)` →  \n",
        "  `Parflex.plot_parflex_with_chunk_S_background(tiled_result, C, flex_wp, stage2_result)`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Parameters\n",
        "\n",
        "Chunk length and other defaults. Override in function calls (e.g. `parflex(..., L=2000)` or `align_system_sparse_parflex(..., L=2000)`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Chunk size for tiling the cost matrix. Drives memory/speed tradeoff.\n",
        "DEFAULT_CHUNK_LENGTH = 4000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import plotly.graph_objects as go\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_parflex_with_chunk_S_background(tiled_result, C_global, flex_wp, parflex_res, xy=None,\n",
        "                                         chunk_length=None, use_valid_edges_only=True):\n",
        "    \"\"\"\n",
        "    Plot FlexDTW vs ParFlex paths. Background: chunk S start→edge segments (global coords).\n",
        "    Foreground: global FlexDTW path, ParFlex stitched path, best-per-segment paths.\n",
        "\n",
        "    chunk_length : used for grid lines; if None, uses tiled_result['L_block'].\n",
        "    \"\"\"\n",
        "    blocks = tiled_result['blocks']\n",
        "    L_block = tiled_result['L_block']\n",
        "    L_div = chunk_length if chunk_length is not None else L_block\n",
        "    hop = tiled_result['hop']\n",
        "    D_chunks = parflex_res['D_chunks']\n",
        "    n_row, n_col = parflex_res['n_row'], parflex_res['n_col']\n",
        "\n",
        "    L1, L2 = C_global.shape\n",
        "    base_px = 900\n",
        "    max_side = max(L1, L2)\n",
        "    scale = base_px / max_side\n",
        "    fig_width = int(max(L2 * scale, 400))\n",
        "    fig_height = int(max(L1 * scale, 400))\n",
        "\n",
        "    fig = go.Figure()\n",
        "\n",
        "    x_S, y_S = [], []\n",
        "    INF = 1e17\n",
        "\n",
        "    def edge_index_to_local_coords(edge, idx, rows, cols):\n",
        "        \"\"\"Edge 0 = top → (rows-1, idx); edge 1 = right → (idx, cols-1).\"\"\"\n",
        "        return (rows - 1, idx) if edge == 0 else (idx, cols - 1)\n",
        "\n",
        "    for b in blocks:\n",
        "        i, j = b['bi'], b['bj']\n",
        "        if i >= n_row or j >= n_col:\n",
        "            continue\n",
        "\n",
        "        S_single = b['S_single']\n",
        "        rows, cols = b['Ck_shape']\n",
        "        r_start, r_end = b['rows']\n",
        "        c_start, c_end = b['cols']\n",
        "\n",
        "        for edge in (0, 1):  # 0=top edge, 1=right edge\n",
        "            edge_len = min(L_block, cols if edge == 0 else rows)\n",
        "\n",
        "            for idx in range(edge_len):\n",
        "                if use_valid_edges_only:\n",
        "                    D_val = D_chunks[i][j][edge][idx]\n",
        "                    if not np.isfinite(D_val) or D_val >= INF:\n",
        "                        continue\n",
        "\n",
        "                lr, lc = edge_index_to_local_coords(edge, idx, rows, cols)\n",
        "                if lr < 0 or lc < 0 or lr >= rows or lc >= cols:\n",
        "                    continue\n",
        "\n",
        "                s_val = S_single[lr, lc]\n",
        "                if s_val > 0:\n",
        "                    start_local_r, start_local_c = 0, int(s_val)\n",
        "                elif s_val < 0:\n",
        "                    start_local_r, start_local_c = abs(int(s_val)), 0\n",
        "                else:\n",
        "                    start_local_r, start_local_c = 0, 0\n",
        "                g_start_r = r_start + start_local_r\n",
        "                g_start_c = c_start + start_local_c\n",
        "                g_end_r   = r_start + lr\n",
        "                g_end_c   = c_start + lc\n",
        "                if not (0 <= g_start_r < L1 and 0 <= g_start_c < L2):\n",
        "                    continue\n",
        "                if not (0 <= g_end_r < L1 and 0 <= g_end_c < L2):\n",
        "                    continue\n",
        "                x_S.extend([g_start_c, g_end_c, None])\n",
        "                y_S.extend([g_start_r, g_end_r, None])\n",
        "\n",
        "    if x_S:\n",
        "        fig.add_trace(\n",
        "            go.Scattergl(\n",
        "                x=x_S,\n",
        "                y=y_S,\n",
        "                mode=\"lines\",\n",
        "                name=\"Chunk S start→edge segments\",\n",
        "                line=dict(width=1, color=\"rgba(100,100,100,0.25)\"),  # equal opacity for all S segments\n",
        "                showlegend=False)\n",
        "        )\n",
        "    stitched_wp = parflex_res['stitched_wp']\n",
        "    if stitched_wp.size > 0:\n",
        "        fig.add_trace(\n",
        "            go.Scattergl(\n",
        "                x=stitched_wp[:, 1],   # cols (F2)\n",
        "                y=stitched_wp[:, 0],   # rows (F1)\n",
        "                mode=\"lines\",\n",
        "                name=\"ParFlex stitched (global best)\",\n",
        "                line=dict(width=6,color=\"rgba(247,14,14,0.5)\")\n",
        "            )\n",
        "        )\n",
        "    paths_per_segment = parflex_res['paths_per_segment']\n",
        "\n",
        "    for (edge_name, seg_idx), info in paths_per_segment.items():\n",
        "        path = np.array(info['path'], dtype=int)\n",
        "        if path.size == 0:\n",
        "            continue\n",
        "        fig.add_trace(\n",
        "            go.Scattergl(\n",
        "                x=path[:, 1],   # col\n",
        "                y=path[:, 0],   # row\n",
        "                mode=\"lines\",\n",
        "                name=f\"{edge_name} seg={seg_idx}\",\n",
        "                line=dict(width=3, color=\"rgba(0,128,255,0.5)\")\n",
        "            )\n",
        "        )\n",
        "    flex_wp = np.asarray(flex_wp)\n",
        "\n",
        "    if flex_wp.shape[1] == 2:\n",
        "        f1_frames = flex_wp[:, 0]\n",
        "        f2_frames = flex_wp[:, 1]\n",
        "    elif flex_wp.shape[0] == 2:\n",
        "        f1_frames = flex_wp[0, :]\n",
        "        f2_frames = flex_wp[1, :]\n",
        "    else:\n",
        "        raise ValueError(f\"Unexpected flex_wp shape: {flex_wp.shape}\")\n",
        "\n",
        "    fig.add_trace(\n",
        "        go.Scattergl(\n",
        "            x=f2_frames,\n",
        "            y=f1_frames,\n",
        "            mode=\"lines\",\n",
        "            name=\"Global FlexDTW\",\n",
        "            line=dict(width=4, color=\"rgba(0,0,0,1)\")\n",
        "        )\n",
        "    )\n",
        "    # if xy is not None:\n",
        "    #     xy_arr = np.asarray(xy)\n",
        "\n",
        "    #     if xy_arr.ndim != 2 or xy_arr.shape[1] != 2:\n",
        "    #         raise ValueError(f\"xy must have shape (N,2), got {xy_arr.shape}\")\n",
        "\n",
        "    #     xy_frames = xy\n",
        "\n",
        "    #     fig.add_trace(\n",
        "    #         go.Scattergl(\n",
        "    #             x=xy_frames[:, 1],   # F2 frames\n",
        "    #             y=xy_frames[:, 0],   # F1 frames\n",
        "    #             mode=\"lines\",\n",
        "    #             name=\"Ground Truth\",\n",
        "    #             line=dict(width=4, dash=\"dash\", color=\"rgba(0,200,0,0.9)\")\n",
        "    #         )\n",
        "    #     )\n",
        "    x_lo, x_hi = -0.5, L2 - 0.5\n",
        "    y_lo, y_hi = -0.5, L1 - 0.5\n",
        "\n",
        "    fig.update_layout(\n",
        "        title=\"Global FlexDTW vs ParFlex (with chunk-S spiky background)\",\n",
        "        xaxis_title=f\"F2 frames (0 … {L2-1})\",\n",
        "        yaxis_title=f\"F1 frames (0 … {L1-1})\",\n",
        "        legend=dict(x=0.01, y=0.99),\n",
        "        width=fig_width,\n",
        "        height=fig_height,\n",
        "        plot_bgcolor=\"white\",\n",
        "        paper_bgcolor=\"white\",\n",
        "    )\n",
        "\n",
        "    fig.update_xaxes(range=[x_lo, x_hi], showgrid=False)\n",
        "    fig.update_yaxes(range=[y_lo, y_hi], showgrid=False)\n",
        "    shapes = []\n",
        "    for x in range(L_div, L2, L_div):\n",
        "        shapes.append(dict(\n",
        "            type=\"line\",\n",
        "            x0=x, x1=x,\n",
        "            y0=y_lo, y1=y_hi,\n",
        "            line=dict(width=1, dash=\"dot\")\n",
        "        ))\n",
        "    for y in range(L_div, L1, L_div):\n",
        "        shapes.append(dict(\n",
        "            type=\"line\",\n",
        "            x0=x_lo, x1=x_hi,\n",
        "            y0=y, y1=y,\n",
        "            line=dict(width=1, dash=\"dot\")\n",
        "        ))\n",
        "    fig.update_layout(shapes=shapes)\n",
        "    fig.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def _start_points_from_S(S):\n",
        "    \"\"\"\n",
        "    From chunk S matrix (P in FlexDTW: signed encoding of path start per cell), compute\n",
        "    unique start points only for the top edge and right edge of the chunk.\n",
        "    Only reads S on last row and last column (no full-matrix scan).\n",
        "    Returns (starts_top_edge, starts_right_edge):\n",
        "      - starts_top_edge: set of column indices (paths ending on top edge that started on row 0 at that col)\n",
        "      - starts_right_edge: set of row indices (paths ending on right edge that started on col 0 at that row)\n",
        "    \"\"\"\n",
        "    rows, cols = S.shape\n",
        "    starts_bottom_edge = set()\n",
        "    starts_left_edge = set()\n",
        "    # Top edge: last row S[rows-1, :]\n",
        "    for c in range(cols):\n",
        "        val = S[rows - 1, c]\n",
        "        if val > 0:\n",
        "            starts_bottom_edge.add(int(val))\n",
        "        else:\n",
        "            # if starts on left or ==0, then it's a left edge start\n",
        "            starts_left_edge.add(abs(int(val)))  # row start; keep for completeness\n",
        "    # Right edge: last column S[:, cols-1]\n",
        "    for r in range(rows):\n",
        "        val = S[r, cols - 1]\n",
        "        if val > 0:\n",
        "            starts_bottom_edge.add(int(val))\n",
        "        else:\n",
        "            # if starts on left or ==0, then it's a left edge start\n",
        "            starts_left_edge.add(abs(int(val)))  # row start; keep for completeness\n",
        "    \n",
        "    return starts_bottom_edge, starts_left_edge"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Chunking and coordinate helpers\n",
        "\n",
        "Split cost matrix into overlapping chunks; run FlexDTW per chunk. Helpers map edge indices to local/global coords and decode FlexDTW start encoding (S)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def chunk_flexdtw(C, L, steps=None, weights=None, buffer=1):\n",
        "    \"\"\"\n",
        "    Break cost matrix C into overlapping chunks and run FlexDTW on each.\n",
        "    Ensures exactly 1-cell overlap between chunks. Last chunks may be smaller\n",
        "    than L×L to maintain the 1-cell overlap constraint.\n",
        "    \n",
        "    Now stores flexible hop information for each chunk to handle boundary truncation.\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    C : ndarray\n",
        "        Cost matrix of shape (L1, L2)\n",
        "    L : int\n",
        "        Standard chunk size\n",
        "    steps : list, optional\n",
        "        Step patterns for DTW\n",
        "    weights : list, optional\n",
        "        Weights for each step pattern\n",
        "    buffer : int\n",
        "        Buffer parameter for FlexDTW\n",
        "        \n",
        "    Returns:\n",
        "    --------\n",
        "    chunks_dict : dict\n",
        "        Dictionary with chunk data, including 'bounds' and 'hop' for each chunk\n",
        "    L : int\n",
        "        Chunk size\n",
        "    n_chunks_1, n_chunks_2 : int\n",
        "        Number of chunks in each dimension\n",
        "    \"\"\"\n",
        "    import math\n",
        "    \n",
        "    if steps is None:\n",
        "        steps = [(1,1), (1,2), (2,1)]\n",
        "    if weights is None:\n",
        "        weights = [2, 3, 3]\n",
        "    \n",
        "    L1, L2 = C.shape\n",
        "    ## print(f\"Matrix shape: {L1} × {L2}\")\n",
        "    hop = L - 1  # Standard overlap of 1\n",
        "    \n",
        "    # Compute number of chunks along each axis\n",
        "    n_chunks_1 = math.ceil((L1 - 1) / hop)\n",
        "    n_chunks_2 = math.ceil((L2 - 1) / hop)\n",
        "    \n",
        "    chunks_dict = {}\n",
        "    \n",
        "    for i in range(n_chunks_1):\n",
        "        for j in range(n_chunks_2):\n",
        "            # Standard start positions with hop size\n",
        "            start_1 = i * hop\n",
        "            start_2 = j * hop\n",
        "            \n",
        "            # Standard end positions\n",
        "            end_1 = start_1 + L\n",
        "            end_2 = start_2 + L\n",
        "            \n",
        "            # For boundary chunks, don't shift start - just truncate end\n",
        "            # This ensures we always have exactly 1-frame overlap\n",
        "            if end_1 > L1:\n",
        "                end_1 = L1\n",
        "            \n",
        "            if end_2 > L2:\n",
        "                end_2 = L2\n",
        "            \n",
        "            # Extract chunk\n",
        "            C_chunk = C[int(start_1):int(end_1), int(start_2):int(end_2)]\n",
        "            \n",
        "            # Run FlexDTW on this chunk\n",
        "            # Note: You'll need to import or have FlexDTW available\n",
        "            # Assuming FlexDTW.flexdtw returns (best_cost, wp, D, P, B, debug)\n",
        "            try:\n",
        "                import FlexDTW\n",
        "                best_cost, wp, D, P, B, debug = FlexDTW.flexdtw(\n",
        "                    C_chunk, \n",
        "                    steps=steps, \n",
        "                    weights=weights, \n",
        "                    buffer=1\n",
        "                )\n",
        "            except ImportError:\n",
        "                # Placeholder if FlexDTW not available\n",
        "                ## print(\"Warning: FlexDTW not imported, using placeholder values\")\n",
        "                best_cost = 0\n",
        "                wp = []\n",
        "                D = np.zeros_like(C_chunk)\n",
        "                P = np.zeros_like(C_chunk)\n",
        "                B = np.zeros_like(C_chunk)\n",
        "                debug = {}\n",
        "            \n",
        "            # Calculate actual hop for this chunk\n",
        "            # For boundary chunks, the hop to the next chunk may be different\n",
        "            actual_hop_1 = hop if end_1 < L1 else (L1 - start_1)\n",
        "            actual_hop_2 = hop if end_2 < L2 else (L2 - start_2)\n",
        "            \n",
        "            \n",
        "            # Unique start points from S (top and right edges only)\n",
        "            starts_bot_edge, starts_left_edge = _start_points_from_S(P)\n",
        "            # print(i,j, \"the chunks\")\n",
        "            # print(len(starts_bot_edge), len(starts_left_edge), \"top, right edge\")\n",
        "            \n",
        "            chunks_dict[(i, j)] = {\n",
        "                'C': C_chunk,\n",
        "                'D': D,\n",
        "                'S': P,  # Start positions (signed encoding)\n",
        "                'B': B,  # Backpointer matrix\n",
        "                'debug': debug,\n",
        "                'best_cost': best_cost,\n",
        "                'wp': wp,\n",
        "                'bounds': (start_1, end_1, start_2, end_2),\n",
        "                'hop': (actual_hop_1, actual_hop_2),  # Store flexible hop sizes\n",
        "                'shape': C_chunk.shape,\n",
        "                'starts_bot_edge': starts_bot_edge,\n",
        "                'starts_left_edge': starts_left_edge,\n",
        "            }\n",
        "            \n",
        "            ## print(f\"Chunk ({i},{j}): [{start_1}:{end_1}, {start_2}:{end_2}], \"\n",
        "                #   f\"shape={C_chunk.shape}, hop=({actual_hop_1},{actual_hop_2}), \"\n",
        "                #   f\"best_cost={best_cost:.4f}\")\n",
        "   \n",
        "    return chunks_dict, L, n_chunks_1, n_chunks_2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def edge_index_to_local_coords(edge_type, position, chunk_shape):\n",
        "    \"\"\"Edge 0 = top → (last_row, position); edge 1 = right → (position, last_col).\"\"\"\n",
        "    if edge_type == 0:\n",
        "        return chunk_shape[0] - 1, position\n",
        "    return position, chunk_shape[1] - 1\n",
        "\n",
        "\n",
        "def local_to_global_coords(chunk_i, chunk_j, local_row, local_col, chunks_dict):\n",
        "    \"\"\"Map (local_row, local_col) in chunk (i, j) to global (row, col).\"\"\"\n",
        "    start_1, _, start_2, _ = chunks_dict[(chunk_i, chunk_j)]['bounds']\n",
        "    return start_1 + local_row, start_2 + local_col\n",
        "\n",
        "\n",
        "def decode_path_start_from_S(S_single, end_row, end_col):\n",
        "    \"\"\"From FlexDTW S encoding at (end_row, end_col): S>0 → start (0, S); S<0 → start (-S, 0); else (0,0).\"\"\"\n",
        "    val = S_single[end_row, end_col]\n",
        "    if val > 0:\n",
        "        return 0, int(val)\n",
        "    if val < 0:\n",
        "        return abs(int(val)), 0\n",
        "    return 0, 0\n",
        "\n",
        "\n",
        "def _on_bottom_edge(start_row, start_col, chunk_shape):\n",
        "    return start_row == 0\n",
        "\n",
        "\n",
        "def _on_left_edge(start_row, start_col, chunk_shape):\n",
        "    return start_col == 0\n",
        "\n",
        "\n",
        "def global_to_prev_chunk_edge(global_row, global_col, prev_chunk_i, prev_chunk_j, chunks_dict, L):\n",
        "    \"\"\"Map global (row, col) to (edge_type, position) on the previous chunk's top or right edge.\"\"\"\n",
        "    start_1, _, start_2, _ = chunks_dict[(prev_chunk_i, prev_chunk_j)]['bounds']\n",
        "    local_row = global_row - start_1\n",
        "    local_col = global_col - start_2\n",
        "    prev_chunk_shape = chunks_dict[(prev_chunk_i, prev_chunk_j)]['D'].shape\n",
        "    if local_row == prev_chunk_shape[0] - 1:\n",
        "        return 0, local_col\n",
        "    if local_col == prev_chunk_shape[1] - 1:\n",
        "        return 1, local_row\n",
        "    raise ValueError(f\"({local_row}, {local_col}) not on edge of previous chunk\")\n",
        "\n",
        "def convert_edge_to_local(edge_type, position, chunk_shape):\n",
        "    \"\"\"\n",
        "    Convert edge representation to local chunk coordinates.\n",
        "    \"\"\"\n",
        "    if edge_type == 0:  # Top edge\n",
        "        return chunk_shape[0] - 1, position  # Last row of actual chunk\n",
        "    else:  # Right edge (edge_type == 1)\n",
        "        return position, chunk_shape[1] - 1  # Last column of actual chunk\n",
        "\n",
        "\n",
        "def get_starting_point(S_single, end_row, end_col):\n",
        "    \"\"\"\n",
        "    Get the starting point for a path ending at (end_row, end_col),\n",
        "    based on the 2D signed encoding from FlexDTW.\n",
        "\n",
        "    If S_single[r, c] > 0 → start on bottom edge: (0, S_single[r, c])\n",
        "    If S_single[r, c] < 0 → start on left edge: (-S_single[r, c], 0)\n",
        "    \"\"\"\n",
        "    val = S_single[end_row, end_col]\n",
        "    \n",
        "    if val > 0:\n",
        "        \n",
        "        return 0, int(val)        # start on bottom edge\n",
        "    elif val < 0:\n",
        "        return abs(int(val)), 0    # start on left edge\n",
        "    else:\n",
        "        return 0, 0  # default / fallback (top-left corner)\n",
        "\n",
        "def convert_local_to_global(chunk_i, chunk_j, local_row, local_col, chunks_dict):\n",
        "    \"\"\"\n",
        "    Convert local chunk coordinates to global matrix coordinates.\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    chunk_i, chunk_j : int, int\n",
        "        Chunk indices\n",
        "    local_row, local_col : int, int\n",
        "        Local coordinates within the chunk\n",
        "    chunks_dict : dict\n",
        "        Dictionary containing chunk data with 'hop' information\n",
        "        \n",
        "    Returns:\n",
        "    --------\n",
        "    global_row, global_col : int, int\n",
        "        Global matrix coordinates\n",
        "    \"\"\"\n",
        "    # Get the starting bounds for this chunk\n",
        "    start_1, _, start_2, _ = chunks_dict[(chunk_i, chunk_j)]['bounds']\n",
        "    \n",
        "    global_row = start_1 + local_row\n",
        "    global_col = start_2 + local_col\n",
        "    return global_row, global_col\n",
        "\n",
        "def is_on_bottom_edge(start_row, start_col, chunk_shape):\n",
        "    \"\"\"Check if starting point is on bottom edge.\"\"\"\n",
        "    return start_row == 0\n",
        "\n",
        "\n",
        "def is_on_left_edge(start_row, start_col, chunk_shape):\n",
        "    \"\"\"Check if starting point is on left edge.\"\"\"\n",
        "    return start_col == 0\n",
        "def _valid_positions(chunk_data, edge_type, edge_len):\n",
        "    \"\"\"\n",
        "    Returns sorted list of valid positions to iterate for a given edge of a chunk.\n",
        "    Always includes 0 and edge_len-1 for continuity.\n",
        "    \n",
        "    edge_type=0 (top edge, indexed by col): uses starts_bot_edge\n",
        "    edge_type=1 (right edge, indexed by row): uses starts_left_edge\n",
        "    \"\"\"\n",
        "    if edge_type == 0:\n",
        "        starts = chunk_data.get('starts_bot_edge', set())\n",
        "    else:\n",
        "        starts = chunk_data.get('starts_left_edge', set())\n",
        "    \n",
        "    # Always include 0 and last position, filter to valid range\n",
        "    positions = set(starts) | {0, edge_len - 1}\n",
        "    positions = {p for p in positions if 0 <= p < edge_len}\n",
        "    return sorted(positions)\n",
        "\n",
        "def _valid_positions(chunks_dict, i, j, edge_type, edge_len, num_chunks_1, num_chunks_2):\n",
        "    \"\"\"\n",
        "    Returns sorted list of valid positions to compute on chunk (i,j)'s edges.\n",
        "    Valid positions are determined by what neighboring chunks need as inputs:\n",
        "    \n",
        "    - edge_type=0 (top/bottom edge, indexed by col): the chunk BELOW (i+1, j) \n",
        "      will start paths at these column positions -> use starts_bot_edge of (i+1, j)\n",
        "    - edge_type=1 (right edge, indexed by row): the chunk to the RIGHT (i, j+1)\n",
        "      will start paths at these row positions -> use starts_left_edge of (i, j+1)\n",
        "    \n",
        "    Always includes 0 and edge_len-1 for continuity.\n",
        "    \"\"\"\n",
        "    starts = set()\n",
        "\n",
        "    if edge_type == 0:\n",
        "        # look at the chunk above\n",
        "        above = (i + 1, j)\n",
        "        if above in chunks_dict:\n",
        "            starts = chunks_dict[above].get('starts_bot_edge', set())\n",
        "    else:\n",
        "        # Chunk to the right needs these row positions as path starts\n",
        "        right = (i, j + 1)\n",
        "        if right in chunks_dict:\n",
        "            starts = chunks_dict[right].get('starts_left_edge', set())\n",
        "    \n",
        "\n",
        "    positions = set(starts) | {0, edge_len - 1}\n",
        "    positions = {p for p in positions if 0 <= p < edge_len}\n",
        "    return sorted(positions)\n",
        "\n",
        "\n",
        "def initialize_chunks(chunks_dict, num_chunks_1, num_chunks_2, L):\n",
        "    \"\"\"\n",
        "    Initialize D_chunks and L_chunks for the first row and first column.\n",
        "    Uses flexible data structure to accommodate non-square boundary chunks.\n",
        "    Ensures edge continuity between adjacent chunks.\n",
        "    Only iterates over valid start positions (sparse) plus endpoints for continuity.\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    chunks_dict : dict\n",
        "        Dictionary containing chunk data (including 'hop' for each chunk)\n",
        "    num_chunks_1, num_chunks_2 : int, int\n",
        "        Number of chunks in each dimension\n",
        "    L : int\n",
        "        Chunk size\n",
        "        \n",
        "    Returns:\n",
        "    --------\n",
        "    D_chunks, L_chunks : list of list of dicts of lists\n",
        "        Indexed as [chunk_row][chunk_col][edge_type][position]\n",
        "        Where position is a Python list that can vary in length\n",
        "    \"\"\"\n",
        "    D_chunks = [[{0: [], 1: []} for _ in range(num_chunks_2)] for _ in range(num_chunks_1)]\n",
        "    L_chunks = [[{0: [], 1: []} for _ in range(num_chunks_2)] for _ in range(num_chunks_1)]\n",
        "\n",
        "    def _edge_length(chunk_shape, edge_type):\n",
        "        return chunk_shape[1] if edge_type == 0 else chunk_shape[0]\n",
        "\n",
        "    # ==================================================================================\n",
        "    # Initialize chunk (0, 0)\n",
        "    # ==================================================================================\n",
        "    D_single_00 = chunks_dict[(0, 0)]['D']\n",
        "    S_single_00 = chunks_dict[(0, 0)]['S']\n",
        "\n",
        "    for edge_type in range(2):\n",
        "        edge_len = _edge_length(D_single_00.shape, edge_type)\n",
        "        D_chunks[0][0][edge_type] = [np.inf] * edge_len\n",
        "        L_chunks[0][0][edge_type] = [np.inf] * edge_len\n",
        "        valid_positions = _valid_positions(chunks_dict, 0, 0, edge_type, edge_len, num_chunks_1, num_chunks_2)\n",
        "        # print(\"Valid positions for chunk (0, 0)\", valid_positions)\n",
        "        for position in valid_positions:\n",
        "            local_row, local_col = edge_index_to_local_coords(edge_type, position, D_single_00.shape)\n",
        "\n",
        "            if local_row < D_single_00.shape[0] and local_col < D_single_00.shape[1]:\n",
        "                start_row, start_col = decode_path_start_from_S(S_single_00, local_row, local_col)\n",
        "\n",
        "                if _on_bottom_edge(start_row, start_col, D_single_00.shape) or \\\n",
        "                   _on_left_edge(start_row, start_col, D_single_00.shape):\n",
        "                    D_chunks[0][0][edge_type][position] = D_single_00[local_row, local_col]\n",
        "                    path_length = abs(local_row - start_row) + abs(local_col - start_col)\n",
        "                    L_chunks[0][0][edge_type][position] = path_length\n",
        "\n",
        "    # ==================================================================================\n",
        "    # CASE 1: Initialize first row - chunks (0, j) for j = 1, 2, ...\n",
        "    # ==================================================================================\n",
        "    for j in range(1, num_chunks_2):\n",
        "        if (0, j) not in chunks_dict:\n",
        "            continue\n",
        "\n",
        "        D_single = chunks_dict[(0, j)]['D']\n",
        "        S_single = chunks_dict[(0, j)]['S']\n",
        "        C_chunk = chunks_dict[(0, j)].get('C', None)\n",
        "\n",
        "        # Edge continuity: 0th index on top edge = previous chunk's last index on top edge\n",
        "        D_chunks[0][j][0] = [D_chunks[0][j-1][0][-1]] + [np.inf] * (_edge_length(D_single.shape, 0) - 1)\n",
        "        L_chunks[0][j][0] = [L_chunks[0][j-1][0][-1]] + [np.inf] * (_edge_length(D_single.shape, 0) - 1)\n",
        "\n",
        "        edge_len_right = _edge_length(D_single.shape, 1)\n",
        "        D_chunks[0][j][1] = [np.inf] * edge_len_right\n",
        "        L_chunks[0][j][1] = [np.inf] * edge_len_right\n",
        "\n",
        "        for edge_type in range(2):\n",
        "            edge_len = _edge_length(D_single.shape, edge_type)\n",
        "            valid_positions_first_row = _valid_positions(chunks_dict, 0, j, edge_type, edge_len, num_chunks_1, num_chunks_2)\n",
        "\n",
        "            if edge_type == 1 and j == num_chunks_2 - 1:\n",
        "                valid_positions_first_row = set(range(edge_len))\n",
        "            if edge_type == 0 and num_chunks_1 == 1:\n",
        "                valid_positions_first_row = set(range(edge_len))\n",
        "            # print(\"_________\")\n",
        "            # print(\"chunk:\", (0, j))\n",
        "            # print(\"length of valid positions first row\", len(valid_positions_first_row))\n",
        "            # print(\"_________\")\n",
        "            for position in valid_positions_first_row:\n",
        "                # Skip position 0 for top edge - already set by continuity\n",
        "                if edge_type == 0 and position == 0:\n",
        "                    continue\n",
        "\n",
        "                local_row, local_col = edge_index_to_local_coords(edge_type, position, D_single.shape)\n",
        "\n",
        "                if local_row >= D_single.shape[0] or local_col >= D_single.shape[1]:\n",
        "                    continue\n",
        "\n",
        "                start_row, start_col = decode_path_start_from_S(S_single, local_row, local_col)\n",
        "\n",
        "                if _on_bottom_edge(start_row, start_col, D_single.shape):\n",
        "                    D_chunks[0][j][edge_type][position] = D_single[local_row, local_col]\n",
        "                    path_length = abs(local_row - start_row) + abs(local_col - start_col)\n",
        "                    L_chunks[0][j][edge_type][position] = path_length\n",
        "\n",
        "                elif _on_left_edge(start_row, start_col, D_single.shape):\n",
        "                    global_start_row, global_start_col = local_to_global_coords(\n",
        "                        0, j, start_row, start_col, chunks_dict\n",
        "                    )\n",
        "                    prev_edge_type, prev_position = global_to_prev_chunk_edge(\n",
        "                        global_start_row, global_start_col, 0, j - 1, chunks_dict, L\n",
        "                    )\n",
        "\n",
        "                    prev_edge_len = len(D_chunks[0][j-1][prev_edge_type])\n",
        "                    if prev_position >= prev_edge_len:\n",
        "                        continue\n",
        "\n",
        "                    prev_cost = D_chunks[0][j-1][prev_edge_type][prev_position]\n",
        "\n",
        "                    if np.isfinite(prev_cost):\n",
        "                        overlap_cost = C_chunk[start_row, 0] if C_chunk is not None else 0\n",
        "                        D_chunks[0][j][edge_type][position] = D_single[local_row, local_col] + prev_cost - overlap_cost\n",
        "                        prev_length = L_chunks[0][j-1][prev_edge_type][prev_position]\n",
        "                        curr_length = abs(local_row - start_row) + abs(local_col - start_col)\n",
        "                        L_chunks[0][j][edge_type][position] = prev_length + curr_length\n",
        "\n",
        "    # ==================================================================================\n",
        "    # CASE 2: Initialize first column - chunks (i, 0) for i = 1, 2, ...\n",
        "    # ==================================================================================\n",
        "    for i in range(1, num_chunks_1):\n",
        "        if (i, 0) not in chunks_dict:\n",
        "            continue\n",
        "\n",
        "        D_single = chunks_dict[(i, 0)]['D']\n",
        "        S_single = chunks_dict[(i, 0)]['S']\n",
        "        C_chunk = chunks_dict[(i, 0)].get('C', None)\n",
        "\n",
        "        # Edge continuity: 0th index on right edge = previous chunk's last index on right edge\n",
        "        D_chunks[i][0][1] = [D_chunks[i-1][0][1][-1]] + [np.inf] * (_edge_length(D_single.shape, 1) - 1)\n",
        "        L_chunks[i][0][1] = [L_chunks[i-1][0][1][-1]] + [np.inf] * (_edge_length(D_single.shape, 1) - 1)\n",
        "\n",
        "        edge_len_top = _edge_length(D_single.shape, 0)\n",
        "        D_chunks[i][0][0] = [np.inf] * edge_len_top\n",
        "        L_chunks[i][0][0] = [np.inf] * edge_len_top\n",
        "\n",
        "        for edge_type in range(2):\n",
        "            edge_len = _edge_length(D_single.shape, edge_type)\n",
        "            valid_positions_first_column = _valid_positions(chunks_dict, i, 0, edge_type, edge_len, num_chunks_1, num_chunks_2) \n",
        "            if edge_type == 0 and i == num_chunks_1 - 1:\n",
        "                valid_positions_first_column = set(range(edge_len))\n",
        "            if edge_type == 1 and num_chunks_2 == 1:\n",
        "                valid_positions_first_column = set(range(edge_len))\n",
        "            # print(\"_________\")\n",
        "            # print(\"chunk:\", (i, 0))\n",
        "            # print(\"valid positions first column\", valid_positions_first_column)\n",
        "            # print(\"length of valid positions first column\", len(valid_positions_first_column))\n",
        "            # print(\"_________\")\n",
        "            for position in valid_positions_first_column:\n",
        "                # Skip position 0 for right edge - already set by continuity\n",
        "                if edge_type == 1 and position == 0:\n",
        "                    continue\n",
        "\n",
        "                local_row, local_col = edge_index_to_local_coords(edge_type, position, D_single.shape)\n",
        "\n",
        "                if local_row >= D_single.shape[0] or local_col >= D_single.shape[1]:\n",
        "                    continue\n",
        "\n",
        "                start_row, start_col = decode_path_start_from_S(S_single, local_row, local_col)\n",
        "\n",
        "                if _on_left_edge(start_row, start_col, D_single.shape):\n",
        "                    D_chunks[i][0][edge_type][position] = D_single[local_row, local_col]\n",
        "                    path_length = abs(local_row - start_row) + abs(local_col - start_col)\n",
        "                    L_chunks[i][0][edge_type][position] = path_length\n",
        "\n",
        "                elif _on_bottom_edge(start_row, start_col, D_single.shape):\n",
        "                    global_start_row, global_start_col = local_to_global_coords(\n",
        "                        i, 0, start_row, start_col, chunks_dict\n",
        "                    )\n",
        "                    prev_edge_type, prev_position = global_to_prev_chunk_edge(\n",
        "                        global_start_row, global_start_col, i - 1, 0, chunks_dict, L\n",
        "                    )\n",
        "\n",
        "                    prev_edge_len = len(D_chunks[i-1][0][prev_edge_type])\n",
        "                    if prev_position >= prev_edge_len:\n",
        "                        continue\n",
        "\n",
        "                    prev_cost = D_chunks[i-1][0][prev_edge_type][prev_position]\n",
        "\n",
        "                    if np.isfinite(prev_cost):\n",
        "                        overlap_cost = C_chunk[0, start_col] if C_chunk is not None else 0\n",
        "                        D_chunks[i][0][edge_type][position] = D_single[local_row, local_col] + prev_cost - overlap_cost\n",
        "                        prev_length = L_chunks[i-1][0][prev_edge_type][prev_position]\n",
        "                        curr_length = abs(local_row - start_row) + abs(local_col - start_col)\n",
        "                        L_chunks[i][0][edge_type][position] = prev_length + curr_length\n",
        "\n",
        "    return D_chunks, L_chunks\n",
        "\n",
        "\n",
        "def dp_fill_chunks(chunks_dict, D_chunks, L_chunks, num_chunks_1, num_chunks_2, L):\n",
        "    \"\"\"\n",
        "    Fill in D_chunks and L_chunks for all interior chunks using dynamic programming.\n",
        "    Uses flexible hop sizes from chunks_dict.\n",
        "    Only iterates over valid start positions (sparse) plus endpoints for continuity.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    chunks_dict : dict\n",
        "        Dictionary containing chunk data (including flexible 'hop' per chunk)\n",
        "    D_chunks, L_chunks : list of list of dicts of lists\n",
        "        Chunk-level cost and length tensors (partially filled)\n",
        "    num_chunks_1, num_chunks_2 : int, int\n",
        "        Number of chunks in each dimension\n",
        "    L : int\n",
        "        Standard chunk size (for reference)\n",
        "    \"\"\"\n",
        "    def _edge_length(chunk_shape, edge_type):\n",
        "        return chunk_shape[1] if edge_type == 0 else chunk_shape[0]\n",
        "    # print(\"Num chunks 1\", num_chunks_1)\n",
        "    # print(\"Num chunks 2\", num_chunks_2)\n",
        "    for i in range(num_chunks_1):\n",
        "        for j in range(num_chunks_2):\n",
        "            if i == 0 or j == 0:\n",
        "                continue\n",
        "            \n",
        "            D_single = chunks_dict[(i, j)]['D']\n",
        "            S_single = chunks_dict[(i, j)]['S']\n",
        "            C_chunk = chunks_dict[(i, j)].get('C', None)\n",
        "\n",
        "            for edge_type in range(2):\n",
        "                edge_len = _edge_length(D_single.shape, edge_type)\n",
        "                D_chunks[i][j][edge_type] = [np.inf] * edge_len\n",
        "                L_chunks[i][j][edge_type] = [np.inf] * edge_len\n",
        "                \n",
        "                # check if it's in the last column or last row:\n",
        "                if edge_type == 1 and j == num_chunks_2 - 1:\n",
        "                    # valid_positions_dp = all the points on the edge\n",
        "                    valid_positions_dp = set(range(edge_len))\n",
        "                elif edge_type == 0 and i == num_chunks_1 - 1:\n",
        "                    # valid_positions_dp = all the points on the edge\n",
        "                    valid_positions_dp = set(range(edge_len))\n",
        "                else:    \n",
        "                    valid_positions_dp = _valid_positions(chunks_dict, i, j, edge_type, edge_len, num_chunks_1, num_chunks_2)\n",
        "                # print(\"_________\")\n",
        "                # print(\"chunk:\", (i, j))\n",
        "                # print(\"edge type\", edge_type)\n",
        "                # print(\"valid positions dp\", valid_positions_dp)\n",
        "                # print(\"length of valid positions dp\", len(valid_positions_dp))\n",
        "                # print(\"_________\")\n",
        "                for position in valid_positions_dp:\n",
        "\n",
        "                    # Position 0: inherit from adjacent chunk for continuity\n",
        "                    if position == 0:\n",
        "                        inherited = False\n",
        "\n",
        "                        if edge_type == 0 and j > 0:\n",
        "                            left_edge_len = len(D_chunks[i][j-1][0])\n",
        "                            if left_edge_len > 0:\n",
        "                                rightmost_pos = left_edge_len - 1\n",
        "                                left_cost = D_chunks[i][j-1][0][rightmost_pos]\n",
        "                                left_length = L_chunks[i][j-1][0][rightmost_pos]\n",
        "                                if np.isfinite(left_cost):\n",
        "                                    D_chunks[i][j][edge_type][position] = left_cost\n",
        "                                    L_chunks[i][j][edge_type][position] = left_length\n",
        "                                    inherited = True\n",
        "\n",
        "                        elif edge_type == 1 and i > 0:\n",
        "                            top_edge_len = len(D_chunks[i-1][j][1])\n",
        "                            if top_edge_len > 0:\n",
        "                                bottommost_pos = top_edge_len - 1\n",
        "                                top_cost = D_chunks[i-1][j][1][bottommost_pos]\n",
        "                                top_length = L_chunks[i-1][j][1][bottommost_pos]\n",
        "                                if np.isfinite(top_cost):\n",
        "                                    D_chunks[i][j][edge_type][position] = top_cost\n",
        "                                    L_chunks[i][j][edge_type][position] = top_length\n",
        "                                    inherited = True\n",
        "\n",
        "                        if inherited:\n",
        "                            continue\n",
        "\n",
        "                    local_row, local_col = edge_index_to_local_coords(edge_type, position, D_single.shape)\n",
        "\n",
        "                    if local_row >= D_single.shape[0] or local_col >= D_single.shape[1]:\n",
        "                        continue\n",
        "\n",
        "                    start_row, start_col = decode_path_start_from_S(S_single, local_row, local_col)\n",
        "\n",
        "                    if _on_bottom_edge(start_row, start_col, D_single.shape):\n",
        "                        prev_i, prev_j = i - 1, j\n",
        "                    elif _on_left_edge(start_row, start_col, D_single.shape):\n",
        "                        prev_i, prev_j = i, j - 1\n",
        "                    else:\n",
        "                        # Path started within this chunk\n",
        "                        D_chunks[i][j][edge_type][position] = D_single[local_row, local_col]\n",
        "                        path_length = abs(local_row - start_row) + abs(local_col - start_col)\n",
        "                        L_chunks[i][j][edge_type][position] = path_length\n",
        "                        continue\n",
        "\n",
        "                    global_start_row, global_start_col = local_to_global_coords(\n",
        "                        i, j, start_row, start_col, chunks_dict\n",
        "                    )\n",
        "                    prev_edge_type, prev_position = global_to_prev_chunk_edge(\n",
        "                        global_start_row, global_start_col, prev_i, prev_j, chunks_dict, L\n",
        "                    )\n",
        "\n",
        "                    prev_edge_len = len(D_chunks[prev_i][prev_j][prev_edge_type])\n",
        "                    if prev_position >= prev_edge_len:\n",
        "                        continue\n",
        "\n",
        "                    prev_cost = D_chunks[prev_i][prev_j][prev_edge_type][prev_position]\n",
        "                    prev_length = L_chunks[prev_i][prev_j][prev_edge_type][prev_position]\n",
        "\n",
        "                    if not np.isfinite(prev_cost):\n",
        "                        continue\n",
        "\n",
        "                    first_cell_cost = C_chunk[start_row, start_col] if C_chunk is not None else 0\n",
        "                    curr_cost_contribution = D_single[local_row, local_col] - first_cell_cost\n",
        "                    curr_length = abs(local_row - start_row) + abs(local_col - start_col)\n",
        "\n",
        "                    D_chunks[i][j][edge_type][position] = prev_cost + curr_cost_contribution\n",
        "                    L_chunks[i][j][edge_type][position] = prev_length + curr_length\n",
        "\n",
        "    return D_chunks, L_chunks\n",
        "def chunked_flexdtw(chunks_dict, L, num_chunks_1, num_chunks_2, buffer_param=0.1):\n",
        "    \"\"\"Propagate cost/length on chunk edges: init first row/col, then DP fill. Returns (D_chunks, L_chunks).\"\"\"\n",
        "    D_chunks, L_chunks = initialize_chunks(chunks_dict, num_chunks_1, num_chunks_2, L) \n",
        "    \n",
        "    D_chunks, L_chunks = dp_fill_chunks(chunks_dict, D_chunks, L_chunks, \n",
        "                                        num_chunks_1, num_chunks_2, L)\n",
        "    \n",
        "    return D_chunks, L_chunks\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Tiled result and Stage 2\n",
        "\n",
        "Convert chunk dict to tiled format for plotting; then run Stage 2 backtrace (best path from chunk edges)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def convert_chunks_to_tiled_result(chunks_dict, L, n_chunks_1, n_chunks_2, C, stage1_params=None):\n",
        "    \"\"\"Convert chunk_flexdtw output to tiled format for plot_parflex_with_chunk_S_background and Stage 2.\"\"\"\n",
        "    L1, L2 = C.shape\n",
        "    hop = L - 1  # Your code uses 1-frame overlap\n",
        "    \n",
        "    # Convert chunks dictionary to list of block dicts\n",
        "    blocks = []\n",
        "    \n",
        "    for (i, j), chunk_data in chunks_dict.items():\n",
        "        # Extract bounds\n",
        "        start_1, end_1, start_2, end_2 = chunk_data['bounds']\n",
        "        rows, cols = chunk_data['shape']\n",
        "        \n",
        "        # Get the warping path (ensure it's in the right format)\n",
        "        wp_local = np.array(chunk_data['wp'])\n",
        "        if wp_local.size == 0:\n",
        "            \n",
        "            continue\n",
        "            \n",
        "        # Ensure wp_local is (N, 2)\n",
        "        if wp_local.ndim == 2 and wp_local.shape[0] == 2:\n",
        "            wp_local = wp_local.T\n",
        "        \n",
        "        # Calculate raw cost and path length\n",
        "        C_chunk = chunk_data['C']\n",
        "        raw_cost_blk = float(C_chunk[wp_local[:, 0], wp_local[:, 1]].sum())\n",
        "        path_len_blk = int(np.abs(np.diff(wp_local, axis=0)).sum(axis=1).sum() + 1)\n",
        "        \n",
        "        # Map local path to global coordinates\n",
        "        wp_global = np.column_stack([\n",
        "            wp_local[:, 0] + start_1,\n",
        "            wp_local[:, 1] + start_2\n",
        "        ])\n",
        "        \n",
        "        block_dict = {\n",
        "            'bi': i,\n",
        "            'bj': j,\n",
        "            'rows': (int(start_1), int(end_1)),\n",
        "            'cols': (int(start_2), int(end_2)),\n",
        "            'Ck_shape': (rows, cols),\n",
        "            'best_cost': float(chunk_data['best_cost']),\n",
        "            'wp_global': wp_global,\n",
        "            'wp_local': wp_local.copy(),\n",
        "            'raw_cost': raw_cost_blk,\n",
        "            'path_len': path_len_blk,\n",
        "            'D_single': chunk_data['D'],\n",
        "            'B_single': chunk_data['B'],\n",
        "            'S_single': chunk_data['S']  # Your 'S' becomes 'S_single'\n",
        "        }\n",
        "        \n",
        "        blocks.append(block_dict)\n",
        "    \n",
        "    # Default stage1 parameters if not provided\n",
        "    if stage1_params is None:\n",
        "        stage1_params = {\n",
        "            'steps': np.array([[1, 1], [1, 2], [2, 1]], dtype=int),\n",
        "            'weights': np.array([1.5, 3.0, 3.0], dtype=float),\n",
        "            'buffer': 1.0\n",
        "        }\n",
        "    \n",
        "    # Build the tiled_result dictionary\n",
        "    tiled_result = {\n",
        "        'C_shape': (L1, L2),\n",
        "        'L_block': L,\n",
        "        'hop': hop,\n",
        "        'n_row': n_chunks_1,\n",
        "        'n_col': n_chunks_2,\n",
        "        'blocks': blocks,\n",
        "        'C': C,\n",
        "        'stage1_params': stage1_params\n",
        "    }\n",
        "    \n",
        "    return tiled_result\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def stage_2_backtrace_compatible(tiled_result, all_blocks, D_chunks, L_chunks, L1, L2,\n",
        "                                  L_block, buffer_stage2=200, top_k=1):\n",
        "    \"\"\"Scan top/right edges for best normalized cost; backtrace and stitch path across chunks. Returns dict with stitched_wp, best_cost, paths_per_segment, etc.\"\"\"\n",
        "    \n",
        "    INF = 1e9\n",
        "    n_row = len(D_chunks)\n",
        "    n_col = len(D_chunks[0]) if n_row > 0 else 0\n",
        "    \n",
        "    def edge_to_local(edge, idx, rows, cols):\n",
        "        \"\"\"Convert edge representation to local coordinates.\"\"\"\n",
        "        if edge == 0:  # top\n",
        "            return rows - 1, idx\n",
        "        else:  # right\n",
        "            return idx, cols - 1\n",
        "    \n",
        "    def backtrace_within_chunk(B_single, steps, start_r, start_c, end_r, end_c, \n",
        "                                global_r_offset, global_c_offset):\n",
        "        \"\"\"\n",
        "        Backtrace from (end_r, end_c) back to (start_r, start_c) within a chunk.\n",
        "        Returns path in GLOBAL coordinates, in END → START order.\n",
        "        \"\"\"\n",
        "        path = []\n",
        "        r, c = end_r, end_c\n",
        "        max_iters = B_single.shape[0] * B_single.shape[1]\n",
        "        iters = 0\n",
        "\n",
        "        while iters < max_iters:\n",
        "            path.append((r + global_r_offset, c + global_c_offset))\n",
        "\n",
        "            if r == start_r and c == start_c:\n",
        "                if len(path) == 0 or path[-1] != (start_r + global_r_offset, start_c + global_c_offset):\n",
        "                    path.append((start_r + global_r_offset, start_c + global_c_offset))\n",
        "                break\n",
        "\n",
        "            step_idx = int(B_single[r, c])\n",
        "            if step_idx < 0 or step_idx >= len(steps):\n",
        "                if (r != start_r or c != start_c):\n",
        "                    path.append((start_r + global_r_offset, start_c + global_c_offset))\n",
        "                break\n",
        "\n",
        "            dr, dc = steps[step_idx]\n",
        "            prev_r = r - dr\n",
        "            prev_c = c - dc\n",
        "\n",
        "            if (prev_r < 0 or prev_c < 0 or \n",
        "                prev_r >= B_single.shape[0] or prev_c >= B_single.shape[1]):\n",
        "                if (r != start_r or c != start_c):\n",
        "                    path.append((start_r + global_r_offset, start_c + global_c_offset))\n",
        "                break\n",
        "\n",
        "            r, c = prev_r, prev_c\n",
        "            iters += 1\n",
        "\n",
        "        if iters >= max_iters:\n",
        "            \n",
        "            if (r != start_r or c != start_c):\n",
        "                path.append((start_r + global_r_offset, start_c + global_c_offset))\n",
        "\n",
        "        return path\n",
        "\n",
        "    def backtrace_and_stitch(start_i, start_j, start_edge, start_idx):\n",
        "        \"\"\"\n",
        "        Backtrack from a specific edge endpoint and stitch across chunks.\n",
        "        Returns the GLOBAL path in START → END order.\n",
        "        \"\"\"\n",
        "        path = []\n",
        "        cur_i, cur_j, cur_edge, cur_idx = start_i, start_j, start_edge, start_idx\n",
        "        steps = tiled_result['stage1_params']['steps']\n",
        "        visited_chunks = set()\n",
        "        stop_reason = None\n",
        "        iteration = 0\n",
        "\n",
        "        while True:\n",
        "            iteration += 1\n",
        "            chunk_key = (cur_i, cur_j, cur_edge, cur_idx)\n",
        "\n",
        "            if chunk_key in visited_chunks:\n",
        "                stop_reason = f\"loop at chunk {chunk_key}\"\n",
        "                break\n",
        "            visited_chunks.add(chunk_key)\n",
        "\n",
        "            if (cur_i, cur_j) not in all_blocks:\n",
        "                stop_reason = f\"missing chunk ({cur_i},{cur_j})\"\n",
        "                break\n",
        "\n",
        "            b = all_blocks[(cur_i, cur_j)]\n",
        "            rows, cols = b['shape']  # Changed from 'Ck_shape'\n",
        "            r_start, r_end, c_start, c_end = b['bounds']  # Changed from separate 'rows' and 'cols'\n",
        "\n",
        "            end_r, end_c = edge_to_local(cur_edge, cur_idx, rows, cols)\n",
        "            S_val = b['S'][end_r, end_c]  # Changed from 'S_single'\n",
        "\n",
        "            if S_val >= 0:\n",
        "                start_r = 0\n",
        "                start_c = int(S_val)\n",
        "            else:\n",
        "                start_r = int(-S_val)\n",
        "                start_c = 0\n",
        "\n",
        "            chunk_path = backtrace_within_chunk(\n",
        "                b['B'], steps, start_r, start_c, end_r, end_c, r_start, c_start\n",
        "            )  # Changed from 'B_single' to 'B'\n",
        "\n",
        "            for pt in chunk_path:\n",
        "                if not path or path[-1] != pt:\n",
        "                    path.append(pt)\n",
        "\n",
        "            g_start_row = r_start + start_r\n",
        "            g_start_col = c_start + start_c\n",
        "\n",
        "            if g_start_row == 0:\n",
        "                stop_reason = f\"hit bottom edge at global row 0, col {g_start_col}\"\n",
        "                break\n",
        "            if g_start_col == 0:\n",
        "                stop_reason = f\"hit left edge at global row {g_start_row}, col 0\"\n",
        "                break\n",
        "\n",
        "            # If we land exactly on the chunk corner (local (0,0)), we explicitly\n",
        "            # jump to the bottom-left chunk and continue from its top-edge corner.\n",
        "            # This avoids ambiguity about whether we should move \"up\" or \"left\".\n",
        "            corner_landed = (start_r == 0 and start_c == 0)\n",
        "\n",
        "            if corner_landed:\n",
        "                prev_i, prev_j = cur_i - 1, cur_j - 1\n",
        "                prev_edge = 0  # top edge\n",
        "            elif S_val >= 0:\n",
        "                prev_i, prev_j = cur_i - 1, cur_j\n",
        "                prev_edge = 0\n",
        "            else:\n",
        "                prev_i, prev_j = cur_i, cur_j - 1\n",
        "                prev_edge = 1\n",
        "             \n",
        "\n",
        "            if prev_i < 0 or prev_j < 0:\n",
        "                stop_reason = f\"corner transition out of bounds to ({prev_i},{prev_j})\"\n",
        "                break\n",
        "\n",
        "            if (prev_i, prev_j) not in all_blocks:\n",
        "                stop_reason = f\"previous chunk ({prev_i},{prev_j}) missing\"\n",
        "                break\n",
        "\n",
        "            prev_b = all_blocks[(prev_i, prev_j)]\n",
        "            prev_r_start, prev_r_end, prev_c_start, prev_c_end = prev_b['bounds']  # Changed from separate tuples\n",
        "            prev_rows, prev_cols = prev_b['shape']  # Changed from 'Ck_shape'\n",
        "\n",
        "            if corner_landed:\n",
        "                # Bottom-left chunk's top-edge corner (its top-right) touches current chunk's corner.\n",
        "                prev_idx = prev_cols - 1\n",
        "                max_prev_idx = prev_cols\n",
        "            else:\n",
        "                prev_lr = g_start_row - prev_r_start\n",
        "                prev_lc = g_start_col - prev_c_start\n",
        "\n",
        "                prev_idx = prev_lc if prev_edge == 0 else prev_lr\n",
        "                max_prev_idx = prev_cols if prev_edge == 0 else prev_rows\n",
        "\n",
        "            if prev_idx < 0 or prev_idx >= max_prev_idx:\n",
        "                stop_reason = f\"prev_idx out of bounds({prev_idx}/{max_prev_idx})\"\n",
        "                break\n",
        "\n",
        "            cur_i, cur_j, cur_edge, cur_idx = prev_i, prev_j, prev_edge, prev_idx\n",
        "\n",
        "            if iteration > 100:\n",
        "                stop_reason = f\"iteration limit ({iteration})\"\n",
        "                break\n",
        "\n",
        "        path = path[::-1]\n",
        "        return path\n",
        "\n",
        "    def global_to_chunk_edge(g_row, g_col):\n",
        "        \"\"\"\n",
        "        Given a GLOBAL (g_row, g_col) on the top or right edge of C_global,\n",
        "        find the corresponding chunk, edge, and local edge index.\n",
        "        \"\"\"\n",
        "        for (bi, bj), b in all_blocks.items():\n",
        "            r_start, r_end, c_start, c_end = b['bounds']  # Changed to unpack all 4 values\n",
        "\n",
        "            if r_start <= g_row < r_end and c_start <= g_col < c_end:\n",
        "                rows, cols = b['shape']  # Changed from 'Ck_shape'\n",
        "                local_r = g_row - r_start\n",
        "                local_c = g_col - c_start\n",
        "\n",
        "                if local_r == rows - 1:\n",
        "                    return (bi, bj, 0, local_c)\n",
        "                elif local_c == cols - 1:\n",
        "                    return (bi, bj, 1, local_r)\n",
        "        return None\n",
        "\n",
        "    top_D = np.full(L2, np.nan)\n",
        "    top_L = np.zeros(L2)\n",
        "    right_D = np.full(L1, np.nan)\n",
        "    right_L = np.zeros(L1)\n",
        "\n",
        "    best_overall_cost = float('inf')\n",
        "    best_overall_end = None\n",
        "    best_per_segment = {}\n",
        "    candidate_endpoints = []\n",
        "\n",
        "    # Scan TOP edge\n",
        "    valid_endpoints_found = 0\n",
        "    buf = int(buffer_stage2)\n",
        "\n",
        "    for g_col in range(L2):\n",
        "        g_row = L1 - 1\n",
        "       \n",
        "        if buf > 0 and g_col < buf: \n",
        "            continue\n",
        "\n",
        "        chunk_info = global_to_chunk_edge(g_row, g_col)\n",
        "        if chunk_info is None: \n",
        "            continue\n",
        "\n",
        "        chunk_i, chunk_j, edge, idx = chunk_info\n",
        "        \n",
        "        # Access D_chunks and L_chunks with flexible structure\n",
        "        if chunk_i >= len(D_chunks) or chunk_j >= len(D_chunks[chunk_i]): \n",
        "            continue\n",
        "        if edge not in D_chunks[chunk_i][chunk_j]: \n",
        "            continue\n",
        "        if idx >= len(D_chunks[chunk_i][chunk_j][edge]): \n",
        "            continue\n",
        "            \n",
        "        D_val = D_chunks[chunk_i][chunk_j][edge][idx]\n",
        "        L_val = L_chunks[chunk_i][chunk_j][edge][idx]\n",
        "         \n",
        "\n",
        "        if D_val >= INF or L_val <= 0: \n",
        "            continue\n",
        "        valid_endpoints_found += 1\n",
        "        norm_cost = D_val / L_val\n",
        "        \n",
        "\n",
        "        top_D[g_col] = D_val\n",
        "        top_L[g_col] = L_val\n",
        "        \n",
        "        if norm_cost < best_overall_cost:\n",
        "            best_overall_cost = norm_cost\n",
        "            best_overall_end = (g_row, g_col, chunk_i, chunk_j, edge, idx)\n",
        "\n",
        "        seg_idx = int(g_col // L_block)\n",
        "        key = ('top', seg_idx)\n",
        "\n",
        "        prev = best_per_segment.get(key)\n",
        "        if (prev is None) or (norm_cost < prev['norm_cost']):\n",
        "            best_per_segment[key] = {\n",
        "                'chunk_i': chunk_i,\n",
        "                'chunk_j': chunk_j,\n",
        "                'edge': edge,\n",
        "                'idx': idx,\n",
        "                'norm_cost': norm_cost,\n",
        "                'global_coord': (g_row, g_col),\n",
        "                'segment': key,\n",
        "            }\n",
        "            \n",
        "        candidate_endpoints.append({\n",
        "            'g_row': g_row,\n",
        "            'g_col': g_col,\n",
        "            'chunk_i': chunk_i,\n",
        "            'chunk_j': chunk_j,\n",
        "            'edge': edge,\n",
        "            'idx': idx,\n",
        "            'norm_cost': norm_cost\n",
        "        })\n",
        "\n",
        "    # Scan RIGHT edge\n",
        "    valid_endpoints_found = 0\n",
        "\n",
        "    for g_row in range(L1):\n",
        "        g_col = L2 - 1\n",
        "\n",
        "        if buf > 0 and g_row < buf:\n",
        "            continue\n",
        "\n",
        "        chunk_info = global_to_chunk_edge(g_row, g_col)\n",
        "        if chunk_info is None:\n",
        "            continue\n",
        "\n",
        "        chunk_i, chunk_j, edge, idx = chunk_info\n",
        "        \n",
        "        # Access with flexible structure\n",
        "        if chunk_i >= len(D_chunks) or chunk_j >= len(D_chunks[chunk_i]):\n",
        "            continue\n",
        "        if edge not in D_chunks[chunk_i][chunk_j]:\n",
        "            continue\n",
        "        if idx >= len(D_chunks[chunk_i][chunk_j][edge]):\n",
        "            continue\n",
        "            \n",
        "        D_val = D_chunks[chunk_i][chunk_j][edge][idx]\n",
        "        L_val = L_chunks[chunk_i][chunk_j][edge][idx]\n",
        "\n",
        "        valid_endpoints_found += 1\n",
        "        norm_cost = D_val / L_val\n",
        "        right_D[g_row] = D_val\n",
        "        right_L[g_row] = L_val\n",
        "        if norm_cost < best_overall_cost:\n",
        "            best_overall_cost = norm_cost\n",
        "            best_overall_end = (g_row, g_col, chunk_i, chunk_j, edge, idx)\n",
        "        seg_idx = int(g_row // L_block)\n",
        "        key = ('right', seg_idx)\n",
        "        prev = best_per_segment.get(key)\n",
        "        if (prev is None) or (norm_cost < prev['norm_cost']):\n",
        "            best_per_segment[key] = {\n",
        "                'chunk_i': chunk_i,\n",
        "                'chunk_j': chunk_j,\n",
        "                'edge': edge,\n",
        "                'idx': idx,\n",
        "                'norm_cost': norm_cost,\n",
        "                'global_coord': (g_row, g_col),\n",
        "                'segment': key,\n",
        "            }\n",
        "        candidate_endpoints.append({\n",
        "            'g_row': g_row,\n",
        "            'g_col': g_col,\n",
        "            'chunk_i': chunk_i,\n",
        "            'chunk_j': chunk_j,\n",
        "            'edge': edge,\n",
        "            'idx': idx,\n",
        "            'norm_cost': norm_cost\n",
        "        })\n",
        "\n",
        "    if not candidate_endpoints:\n",
        "        raise ValueError(\"Stage 2: No valid endpoint found on global top/right edges.\")\n",
        "\n",
        "    candidate_endpoints_sorted = sorted(candidate_endpoints, key=lambda c: c['norm_cost'])\n",
        "\n",
        "    best = candidate_endpoints_sorted[0]\n",
        "    best_overall_cost = best['norm_cost'] \n",
        "    best_overall_end = (\n",
        "        best['g_row'], best['g_col'], best['chunk_i'], \n",
        "        best['chunk_j'], best['edge'], best['idx']\n",
        "    )\n",
        "\n",
        "    g_row, g_col, best_i, best_j, best_edge, best_idx = best_overall_end\n",
        "\n",
        "    K = min(top_k, len(candidate_endpoints_sorted))\n",
        "    \n",
        "    # Compute normalized arrays\n",
        "    top_norm = np.full(L2, np.nan)\n",
        "    right_norm = np.full(L1, np.nan)\n",
        "\n",
        "    top_mask = (top_L > 0) & np.isfinite(top_D)\n",
        "    right_mask = (right_L > 0) & np.isfinite(right_D)\n",
        "\n",
        "    top_norm[top_mask] = top_D[top_mask] / top_L[top_mask]\n",
        "    right_norm[right_mask] = right_D[right_mask] / right_L[right_mask]\n",
        "\n",
        "    # Backtrace per segment\n",
        "    paths_per_segment = {}\n",
        " \n",
        "\n",
        "    for seg_key, meta in best_per_segment.items():\n",
        "        ci = meta['chunk_i']\n",
        "        cj = meta['chunk_j']\n",
        "        ce = meta['edge']\n",
        "        cidx = meta['idx']\n",
        "        norm_cost = meta['norm_cost']\n",
        "        g_row, g_col = meta['global_coord']\n",
        "\n",
        "        path = backtrace_and_stitch(ci, cj, ce, cidx)\n",
        "        path_len = len(path)\n",
        "\n",
        "        paths_per_segment[seg_key] = {\n",
        "            'endpoint': meta,\n",
        "            'path': path\n",
        "        }\n",
        "\n",
        "    # Get best overall path\n",
        "    stitched_wp = np.array([], dtype=int).reshape(0, 2)\n",
        "    if best_overall_end is not None:\n",
        "        g_row, g_col, best_i, best_j, best_edge, best_idx = best_overall_end\n",
        "        best_path = backtrace_and_stitch(best_i, best_j, best_edge, best_idx)\n",
        "        if best_path:\n",
        "            stitched_wp = np.array(best_path, dtype=int)\n",
        "\n",
        "    return {\n",
        "        'D_chunks': D_chunks,\n",
        "        'L_chunks': L_chunks,\n",
        "        'best_cost': best_overall_cost,\n",
        "        'best_end': best_overall_end,\n",
        "        'stitched_wp': stitched_wp,\n",
        "        'n_row': n_row,\n",
        "        'n_col': n_col,\n",
        "        'edge_summary': {\n",
        "            'top':   {'D': top_D,   'L': top_L,   'norm': top_norm},\n",
        "            'right': {'D': right_D, 'L': right_L, 'norm': right_norm},\n",
        "        },\n",
        "        'best_per_segment': best_per_segment,\n",
        "        'paths_per_segment': paths_per_segment,\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Sync and public API\n",
        "\n",
        "Sync overlapping edge values; then **align_system_sparse_parflex** (Stage 1) and **sparse_parflex_2a** (Stage 2). **parflex** runs both in one call."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_normalized_global_edge_cost(D_chunks, L_chunks, num_chunks_1, num_chunks_2):\n",
        "    \"\"\"\n",
        "    Plot normalized accumulated cost (Cost / Length) along the global top and right edges.\n",
        "    Traversal order: Top-Left -> Top-Right -> Bottom-Right.\n",
        "    \"\"\"\n",
        "    i_top = num_chunks_1 - 1\n",
        "    j_right = num_chunks_2 - 1\n",
        "    global_edge_data = []\n",
        "    for j in range(num_chunks_2):\n",
        "        costs = np.array(D_chunks[i_top][j][0][1:])\n",
        "        lengths = np.array(L_chunks[i_top][j][0][1:])\n",
        "        valid_indices = np.isfinite(costs) & (lengths > 0)\n",
        "        normalized_costs = np.full_like(costs, np.nan, dtype=float)\n",
        "        normalized_costs[valid_indices] = costs[valid_indices] / lengths[valid_indices]\n",
        "        for cost in normalized_costs:\n",
        "            global_edge_data.append((cost, 'Top'))\n",
        "    for i in range(num_chunks_1 - 1, -1, -1):\n",
        "        costs = np.array(D_chunks[i][j_right][1][1:])\n",
        "        lengths = np.array(L_chunks[i][j_right][1][1:])\n",
        "        valid_indices = np.isfinite(costs) & (lengths > 0)\n",
        "        normalized_costs = np.full_like(costs, np.nan, dtype=float)\n",
        "        normalized_costs[valid_indices] = costs[valid_indices] / lengths[valid_indices]\n",
        "        for cost in normalized_costs[::-1]:\n",
        "            global_edge_data.append((cost, 'Right'))\n",
        "    costs = [d[0] for d in global_edge_data]\n",
        "    edge_types = [d[1] for d in global_edge_data]\n",
        "    top_costs = [costs[i] for i, e in enumerate(edge_types) if e == \"Top\"]\n",
        "    right_costs = [costs[i] for i, e in enumerate(edge_types) if e == \"Right\"]\n",
        "    top_x = np.arange(-len(top_costs), 0)\n",
        "    right_x = np.arange(1, len(right_costs) + 1)\n",
        "    plt.figure(figsize=(15, 6))\n",
        "    plt.plot(top_x, top_costs, label='Global Top Edge', color='C0', linewidth=2)\n",
        "    plt.scatter(top_x, top_costs, color='C0', s=10)\n",
        "    plt.plot(right_x, right_costs, label='Global Right Edge', color='C3', linewidth=2)\n",
        "    plt.scatter(right_x, right_costs, color='C3', s=10)\n",
        "    plt.axvline(x=0, color='gray', linestyle='--', alpha=0.7, label='Corner (0)')\n",
        "    plt.title(\"Normalized Accumulated Cost (Cost / Length) along Global Edge\", fontsize=14)\n",
        "    plt.xlabel(f\"Global Edge Position Index (Total Points: {len(costs)})\", fontsize=12)\n",
        "    plt.ylabel(\"Normalized Cost (Accumulated Cost / Path Length)\", fontsize=12)\n",
        "    plt.legend()\n",
        "    plt.grid(True, which='both', linestyle=':', alpha=0.6)\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "def sync_overlapping_positions(D_chunks, L_chunks, num_chunks_1, num_chunks_2):\n",
        "    \"\"\"Ensure 1-cell overlaps between chunks share the same D/L values.\"\"\"\n",
        "    sync_count = 0\n",
        "\n",
        "    # Horizontal overlaps: chunk[i][j] top[-1] <-> chunk[i][j+1] top[0]\n",
        "    for i in range(num_chunks_1):\n",
        "        for j in range(num_chunks_2 - 1):\n",
        "            if len(D_chunks[i][j][0]) > 0 and len(D_chunks[i][j + 1][0]) > 0:\n",
        "                last_pos = len(D_chunks[i][j][0]) - 1\n",
        "                D_left = D_chunks[i][j][0][last_pos]\n",
        "                D_right = D_chunks[i][j + 1][0][0]\n",
        "\n",
        "                if np.isfinite(D_left) and not np.isfinite(D_right):\n",
        "                    D_chunks[i][j + 1][0][0] = D_left\n",
        "                    L_chunks[i][j + 1][0][0] = L_chunks[i][j][0][last_pos]\n",
        "                    sync_count += 1\n",
        "                elif not np.isfinite(D_left) and np.isfinite(D_right):\n",
        "                    D_chunks[i][j][0][last_pos] = D_right\n",
        "                    L_chunks[i][j][0][last_pos] = L_chunks[i][j + 1][0][0]\n",
        "                    sync_count += 1\n",
        "\n",
        "    # Vertical overlaps: chunk[i][j] right[-1] <-> chunk[i+1][j] right[0]\n",
        "    for i in range(num_chunks_1 - 1):\n",
        "        for j in range(num_chunks_2):\n",
        "            if len(D_chunks[i][j][1]) > 0 and len(D_chunks[i + 1][j][1]) > 0:\n",
        "                last_pos = len(D_chunks[i][j][1]) - 1\n",
        "                D_bottom = D_chunks[i][j][1][last_pos]\n",
        "                D_top = D_chunks[i + 1][j][1][0]\n",
        "\n",
        "                if np.isfinite(D_bottom) and not np.isfinite(D_top):\n",
        "                    D_chunks[i + 1][j][1][0] = D_bottom\n",
        "                    L_chunks[i + 1][j][1][0] = L_chunks[i][j][1][last_pos]\n",
        "                    sync_count += 1\n",
        "                elif not np.isfinite(D_bottom) and np.isfinite(D_top):\n",
        "                    D_chunks[i][j][1][last_pos] = D_top\n",
        "                    L_chunks[i][j][1][last_pos] = L_chunks[i + 1][j][1][0]\n",
        "                    sync_count += 1\n",
        "\n",
        "    # Within-chunk corner: chunk[i][j] top[-1] must equal chunk[i][j] right[-1]\n",
        "    for i in range(num_chunks_1):\n",
        "        for j in range(num_chunks_2):\n",
        "            if len(D_chunks[i][j][0]) > 0 and len(D_chunks[i][j][1]) > 0:\n",
        "                D_top_corner = D_chunks[i][j][0][-1]\n",
        "                D_right_corner = D_chunks[i][j][1][-1]\n",
        "\n",
        "                if np.isfinite(D_top_corner) and not np.isfinite(D_right_corner):\n",
        "                    D_chunks[i][j][1][-1] = D_top_corner\n",
        "                    L_chunks[i][j][1][-1] = L_chunks[i][j][0][-1]\n",
        "                    sync_count += 1\n",
        "                elif not np.isfinite(D_top_corner) and np.isfinite(D_right_corner):\n",
        "                    D_chunks[i][j][0][-1] = D_right_corner\n",
        "                    L_chunks[i][j][0][-1] = L_chunks[i][j][1][-1]\n",
        "                    sync_count += 1\n",
        "                elif np.isfinite(D_top_corner) and np.isfinite(D_right_corner):\n",
        "                    if not np.isclose(D_top_corner, D_right_corner):\n",
        "                        # Prefer top corner value for determinism\n",
        "                        D_chunks[i][j][1][-1] = D_top_corner\n",
        "                        L_chunks[i][j][1][-1] = L_chunks[i][j][0][-1]\n",
        "                        sync_count += 1\n",
        "\n",
        "    # if sync_count > 0:\n",
        "        # print(f\"Synced {sync_count} overlapping positions\")\n",
        "\n",
        "    return D_chunks, L_chunks\n",
        "\n",
        "\n",
        "def align_system_sparse_parflex(F1, F2, steps=None, weights=None, beta=0.1, L=None):\n",
        "    \"\"\"Stage 1 only: build C, chunk with FlexDTW, return (C, tiled_result). L defaults to DEFAULT_CHUNK_LENGTH.\"\"\"\n",
        "    if L is None:\n",
        "        L = DEFAULT_CHUNK_LENGTH\n",
        "    import FlexDTW\n",
        "    C = 1 - FlexDTW.L2norm(F1).T @ FlexDTW.L2norm(F2)\n",
        "    steps = steps if steps is not None else np.array([[1, 1], [1, 2], [2, 1]])\n",
        "    weights = weights if weights is not None else np.array([1.25, 3.0, 3.0])\n",
        "    steps_arr = np.array(steps).reshape((-1, 2))\n",
        "    stage1_params = {'steps': steps_arr, 'weights': np.array(weights), 'buffer': 1.0}\n",
        "    S = chunk_flexdtw(C, L=L, steps=steps, weights=weights, buffer=1)\n",
        "\n",
        "    chunks_dict, L_out, n_chunks_1, n_chunks_2 = chunk_flexdtw(C, L=L, steps=steps, weights=weights, buffer=1)\n",
        "    tiled_result = convert_chunks_to_tiled_result(\n",
        "        chunks_dict, L_out, n_chunks_1, n_chunks_2, C, stage1_params=stage1_params\n",
        "    )\n",
        "    tiled_result['chunks_dict'] = chunks_dict\n",
        "    return C, tiled_result\n",
        "\n",
        "\n",
        "def sparse_parflex_2a(tiled_result, C, beta=0.1, show_fig=False, top_k=1):\n",
        "    \"\"\"Run Parflex Stage 2: propagate costs and backtrace. Returns dict with stitched_wp, best_cost, etc.\"\"\"\n",
        "    chunks_dict = tiled_result['chunks_dict']\n",
        "    L1, L2 = C.shape\n",
        "    L = tiled_result['L_block']\n",
        "    n_chunks_1, n_chunks_2 = tiled_result['n_row'], tiled_result['n_col']\n",
        "    D_chunks, L_chunks = chunked_flexdtw(chunks_dict, L, n_chunks_1, n_chunks_2, buffer_param=1)\n",
        "    D_chunks, L_chunks = sync_overlapping_positions(D_chunks, L_chunks, n_chunks_1, n_chunks_2)\n",
        "    buffer_global = min(L1, L2) * (1 - (1 - beta) * min(L1, L2) / max(L1, L2))\n",
        "    r = stage_2_backtrace_compatible(\n",
        "        tiled_result, chunks_dict, D_chunks, L_chunks, L1, L2,\n",
        "        L_block=L, buffer_stage2=buffer_global, top_k=top_k\n",
        "    )\n",
        "    if show_fig:\n",
        "        plot_normalized_global_edge_cost(D_chunks, L_chunks, n_chunks_1, n_chunks_2)\n",
        "    return r\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def parflex(C, steps, weights, beta, L=None):\n",
        "    \"\"\"Run Parflex on cost matrix C. Returns (best_cost, wp) with wp shape (2, N). L defaults to DEFAULT_CHUNK_LENGTH.\"\"\"\n",
        "    if L is None:\n",
        "        L = DEFAULT_CHUNK_LENGTH\n",
        "    L1, L2 = C.shape\n",
        "    buffer_global = min(L1, L2) * (1 - (1 - beta) * min(L1, L2) / max(L1, L2))\n",
        "\n",
        "    steps_arr = np.array(steps).reshape((-1, 2)) if hasattr(steps, '__len__') else np.array(steps)\n",
        "    weights_arr = np.array(weights)\n",
        "    stage1_params = {'steps': steps_arr, 'weights': weights_arr, 'buffer': 1.0}\n",
        "\n",
        "    chunks_dict, L_out, n_chunks_1, n_chunks_2 = chunk_flexdtw(C, L=L, steps=steps, weights=weights, buffer=1)\n",
        "    tiled_result = convert_chunks_to_tiled_result(\n",
        "        chunks_dict, L_out, n_chunks_1, n_chunks_2, C, stage1_params=stage1_params\n",
        "    )\n",
        "\n",
        "    D_chunks, L_chunks = chunked_flexdtw(chunks_dict, L_out, n_chunks_1, n_chunks_2, buffer_param=1)\n",
        "    D_chunks, L_chunks = sync_overlapping_positions(D_chunks, L_chunks, n_chunks_1, n_chunks_2)\n",
        "\n",
        "    r = stage_2_backtrace_compatible(\n",
        "        tiled_result, chunks_dict, D_chunks, L_chunks, L1, L2,\n",
        "        L_block=L, buffer_stage2=buffer_global, top_k=1\n",
        "    )\n",
        "    wp = r[\"stitched_wp\"]\n",
        "    if wp.size > 0:\n",
        "        wp = wp.T  # (N, 2) -> (2, N)\n",
        "    else:\n",
        "        wp = np.array([[], []], dtype=np.int64)\n",
        "    return r[\"best_cost\"], wp\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import os\n",
        "# import numpy as np\n",
        "# import import_ipynb\n",
        "# import Parflex\n",
        "# import FlexDTW\n",
        "# from pathlib import Path\n",
        "# try:\n",
        "#     from termcolor import colored\n",
        "# except ImportError:\n",
        "#     def colored(s, _): return s\n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import Parflex\n",
        "\n",
        "# # Set these to the exact pair where you observe the \"vertical teleport\" in ParFlex.\n",
        "# # (You mentioned you have two recordings; swap these paths to those two files.)\n",
        "# file_1 = \"/home/ijain/ttmp/Chopin_Mazurkas_features/subseq_30/Chopin_Op017No4/Chopin_Op017No4_Levy-1951_pid915406-13.npy\"\n",
        "# file_2 = \"/home/ijain/ttmp/Chopin_Mazurkas_features/matching/Chopin_Op017No4/Chopin_Op017No4_Afanassiev-2001_pid9130-01.npy\"\n",
        "# # file_1 = \"/home/ijain/ttmp/Chopin_Mazurkas_features/post_5/Chopin_Op017No4/Chopin_Op017No4_Szpilman-1948_pid9147-12.npy\" \n",
        "# # file_2 = \"/home/ijain/ttmp/Chopin_Mazurkas_features/post_5/Chopin_Op017No4/Chopin_Op017No4_Afanassiev-2001_pid9130-01.npy\"  \n",
        "  \n",
        "# # Ensure parameters exist (so this cell is runnable standalone)\n",
        "# try:\n",
        "#     steps\n",
        "# except NameError:\n",
        "#     steps = {\"flexdtw\": np.array([[1, 1], [1, 2], [2, 1]], dtype=int)}\n",
        "\n",
        "# try:\n",
        "#     weights\n",
        "# except NameError:\n",
        "#     weights = {\"flexdtw\": np.array([1.25, 3.0, 3.0], dtype=float)}\n",
        "\n",
        "# try:\n",
        "#     other_params\n",
        "# except NameError:\n",
        "#     other_params = {\"flexdtw\": {\"beta\": 0.1}}\n",
        "\n",
        "# # Load the files\n",
        "# F1 = np.load(file_1, allow_pickle=True)\n",
        "# F2 = np.load(file_2, allow_pickle=True)\n",
        "\n",
        "# L1 = F1.shape[1]\n",
        "# L2 = F2.shape[1]\n",
        " \n",
        "# # ----------------- GLOBAL FLEXDTW PATH -----------------\n",
        "# C_full = 1.0 - FlexDTW.L2norm(F1).T @ FlexDTW.L2norm(F2)\n",
        "# buffer_flex = min(L1, L2) * (1 - (1 - other_params['flexdtw']['beta']) * min(L1, L2) / max(L1, L2))\n",
        "# # print(buffer_flex)\n",
        "# best_cost_full, global_flex_path, D, P, B, debug = FlexDTW.flexdtw(\n",
        "#     C_full,\n",
        "#     steps=steps['flexdtw'],\n",
        "#     weights=weights['flexdtw'],\n",
        "#     buffer=buffer_flex,\n",
        "# )\n",
        "# S = P  # P is the start encoding (used for grey start→endpoint background)\n",
        "# # print(f\"Global FlexDTW path shape: {global_flex_path.shape}\")\n",
        "\n",
        "# # FlexDTW plot: grey = possible starts per global endpoint, black = selected path, dotted grid like Parflex\n",
        "# # FlexDTW plot overlays:\n",
        "# # - grey = possible starts per global endpoint (from P)\n",
        "# # - black = selected global FlexDTW path\n",
        "# # (chunk-based overlays are drawn after we build chunks via Parflex stage-1)\n",
        "# # sparse_parflex.plot_flex_with_global_S_background(\n",
        "# #     C_global=C_full,\n",
        "# #     flex_wp=global_flex_path,\n",
        "# #     S=S,\n",
        "# #     L_div=4000,\n",
        "# #     title=\"Global FlexDTW with S-based start→endpoint background\",\n",
        "# # )\n",
        "\n",
        "\n",
        "# # ----------------- PARFLEX -----------------\n",
        "\n",
        "# C, tiled_result = Parflex.align_system_parflex(\n",
        "#     F1,\n",
        "#     F2,\n",
        "#     steps=steps['flexdtw'],\n",
        "#     weights=weights['flexdtw'],\n",
        "#     beta=other_params['flexdtw']['beta'],\n",
        "# )\n",
        "\n",
        "# # print(\"\\n\" + \"=\" * 80)\n",
        "# # print(\"STAGE 1 COMPLETE - TESTING RESULTS\")\n",
        "# # print(\"=\" * 80)\n",
        "\n",
        "# stage2_result_parflex = Parflex.parflex_2a(\n",
        "#     tiled_result,\n",
        "#     C,\n",
        "#     beta=other_params['flexdtw']['beta'],\n",
        "#     show_fig=False,\n",
        "#     top_k=1,\n",
        "# )\n",
        "\n",
        "\n",
        "# # Aligning system sparse parflex:\n",
        "# C, tiled_result = align_system_sparse_parflex(\n",
        "#     F1,\n",
        "#     F2,\n",
        "#     steps=steps['flexdtw'],\n",
        "#     weights=weights['flexdtw'],\n",
        "#     beta=other_params['flexdtw']['beta'],\n",
        "# )\n",
        "# # print(f\"Number of chunks: {tiled_result['n_row']}×{tiled_result['n_col']}\")\n",
        "\n",
        "# # print(\"\\n\" + \"=\" * 80)\n",
        "# # print(\"STAGE 1 COMPLETE - TESTING RESULTS\")\n",
        "# # print(\"=\" * 80)\n",
        "\n",
        "# stage2_result_sparse = sparse_parflex_2a(\n",
        "#     tiled_result,\n",
        "#     C,\n",
        "#     beta=other_params['flexdtw']['beta'],\n",
        "#     show_fig=False,\n",
        "#     top_k=1,\n",
        "# )\n",
        "\n",
        "# # compare numberically stage2_result_sparse and stage2_result_parflex's ['stitched_wp']\n",
        "# # comparisons = np.allclose(stage2_result_sparse['stitched_wp'], stage2_result_parflex['stitched_wp'])\n",
        "# # # print(comparisons)\n",
        "\n",
        "\n",
        "# plot_parflex_with_chunk_S_background(\n",
        "#     tiled_result, C, global_flex_path, stage2_result_sparse,\n",
        "#     xy=None\n",
        "# )\n",
        "# plot_parflex_with_chunk_S_background(\n",
        "#     tiled_result, C, global_flex_path, stage2_result_parflex,\n",
        "#     xy=None\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "# start_mat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "# s = start_mat[-1]\n",
        "\n",
        "# # # print length of lASt row\n",
        "# # print(len(start_mat[-1]))\n",
        "# # print(len(set(start_mat[-1])))\n",
        "# unique_top_vals = np.unique(start_mat[-1])\n",
        "# # print(unique_top_vals)\n",
        "# # print(len(unique_top_vals))\n",
        "\n",
        "# unique_right_vals = np.unique(start_mat[:, -1])\n",
        "# # print(unique_right_vals)\n",
        "# # print(len(unique_right_vals))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # get the last column of start_mat\n",
        "# # get first row of start_mat\n",
        "# s_row = start_mat[0]\n",
        "# s_col = start_mat[:,-1]\n",
        "# left_row, bot_row = 0, 0\n",
        "# left_col, bot_col = 0, 0\n",
        "# # count the number of positive and negative values in s\n",
        "# for i in s_row: \n",
        "#     if i > 0: \n",
        "#         left_row += 1\n",
        "#         left_col += 1\n",
        "#     else:\n",
        "#         bot_row += 1\n",
        "#         bot_col += 1\n",
        "# # print(\"row\")\n",
        "# # print(left_row)\n",
        "# # print(bot_row)\n",
        "# # print(\"col\")\n",
        "# # print(left_col)\n",
        "# # print(bot_col)\n",
        "\n",
        "\n",
        "        \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "# start_mat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "# left, bot = 0, 0\n",
        "# for i in s: \n",
        "#     if i > 0: \n",
        "#         left += 1 \n",
        "#     else:\n",
        "#         bot += 1\n",
        "# # print(left)\n",
        "# # print(bot)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "mir",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
